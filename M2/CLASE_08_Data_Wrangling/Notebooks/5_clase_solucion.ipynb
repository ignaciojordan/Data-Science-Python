{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "\n",
    "    # si usan colab, deben cambiar el token de esta url\n",
    "    ! mkdir -p ../Data\n",
    "    # los que usan colab deben modificar el token de estas urls:\n",
    "    ! wget -O ../Data/tags.csv https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_students_2020/master/M2/CLASE_08_Data_Wrangling/Data/tags.csv?token=AA4GFHL5DGGO66Z3XHVBCCS6V4IRM\n",
    "    ! wget -O ../Data/movies.csv https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_students_2020/master/M2/CLASE_08_Data_Wrangling/Data/movies.csv?token=AA4GFHNVLL665P4RLTZNUVS6V4IUK\n",
    "    ! wget -O ../Data/ratings.csv https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_students_2020/master/M2/CLASE_08_Data_Wrangling/Data/ratings.csv?token=AA4GFHKROGU63T3BVY7C6W26V4IXE\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Data wrangling es el proceso de limpieza y unificación de conjuntos de datos desordenados y complejos para facilitar su acceso, exploración, análisis o modelización posterior.\n",
    "\n",
    "Las tareas que involucra son\n",
    "* Limpieza de datos\n",
    "* Eliminación de registros duplicados\n",
    "* Transformación de datos\n",
    "* Discretización de variables\n",
    "* Detección y filtro de outliers\n",
    "* Construcción de variables dummies\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "En esta clase usaremos un dataset con info de películas que disponibiliza datos de movielens (https://movielens.org/).\n",
    "\n",
    "https://grouplens.org/datasets/movielens/\n",
    "\n",
    "http://files.grouplens.org/datasets/movielens/ml-latest-small.zip\n",
    "\n",
    "Este conjunto de datos está conformado por varios archivos:\n",
    "* **movies**: idPelicula, título y género; \n",
    "\n",
    "donde cada registro tiene los datos de una película\n",
    "\n",
    "* **ratings**: idUsuario, idPelicula, rating, fecha; \n",
    "\n",
    "donde cada registro tienen la calificación otorgada por un usuario a una película\n",
    "\n",
    "* **tags**: idUsuario, idPelicula, tag, fecha; \n",
    "\n",
    "donde cada registro tienen el tag que asignó un usuario a una película\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1  - Importar \n",
    "\n",
    "Leamos los datos de movies, ratings y tags desde los archivos\n",
    "* ../Data/movies.csv\n",
    "* ../Data/ratings.csv\n",
    "* ../Data/tags.csv\n",
    "\n",
    "en las variables \n",
    "* data_movies\n",
    "* data_ratings\n",
    "* data_tags\n",
    "\n",
    "Veamos cuántos registros hay en cada DataFrame y de qué tipos son los datos de cada columna. \n",
    "\n",
    "Veamos los primeros registros de cada DataFrame para verificar que los datos fueron importados correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ratings = pd.read_csv(\"../Data/ratings.csv\", sep=\",\")\n",
    "print(data_ratings.dtypes)\n",
    "data_ratings.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tags = pd.read_csv(\"../Data/tags.csv\", sep=\",\")\n",
    "print(data_tags.dtypes)\n",
    "data_tags.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_movies = pd.read_csv(\"../Data/movies.csv\", sep=\",\")\n",
    "print(data_movies.dtypes)\n",
    "data_movies.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2  - Registros duplicados\n",
    "\n",
    "**2.a** Veamos si existen registros duplicados en el DataFrame data_tags considerando sólo las columnas \"movieId\", \"tag\", marcando como no duplicado la primera ocurrencia de un valor.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html\n",
    "\n",
    "\n",
    "**2.b** Usemos el método `drop_duplicates` para obtener otro  `DataFrame` sin los casos duplicados considerando sólo las columnas \"movieId\", \"tag\". Usemos el método `duplicated` para verificar que el nuevo `DataFrame` efectivamente no tiene valores duplicados.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop_duplicates.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_mask = data_tags.duplicated(subset = [ \"movieId\", \"tag\"], keep = \"first\")\n",
    "\n",
    "print(type(duplicated_mask))\n",
    "\n",
    "print(any(duplicated_mask))\n",
    "\n",
    "duplicated_records = data_tags.loc[duplicated_mask]\n",
    "duplicated_records.sort_values(by=[\"movieId\", \"tag\"]).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tags_nodup = data_tags.drop_duplicates(subset = [\"movieId\", \"tag\"], keep = \"first\")\n",
    "print(data_tags.shape)\n",
    "print(data_tags_nodup.shape)\n",
    "\n",
    "dup_mask = data_tags_nodup.duplicated(subset = [\"movieId\", \"tag\"], keep = \"first\")\n",
    "any(dup_mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Transformar datos\n",
    "\n",
    "Construyamos un diccionario que asocie un puntaje a una etiqueta.\n",
    "\n",
    "Las etiquetas son:\n",
    "\n",
    "* mala, para puntajes menores a 3;\n",
    "\n",
    "* regular, para mayor igual a 3 y  menor que 4;\n",
    "\n",
    "* buena para puntaje mayor o igual que 4\n",
    "\n",
    "Usemos el método `map` para crear una nueva columna en data (`rating_label`) que tenga las etiquetas asociadas al valor del campo `rating` para cada registro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(data_ratings.rating.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etiquetas = { 0.5: \"mala\",\n",
    "             1:  \"mala\",\n",
    "             1.5:  \"mala\",\n",
    "             2:  \"mala\",\n",
    "             2.5:  \"mala\",\n",
    "             3: \"regular\",\n",
    "             3.5: \"regular\",\n",
    "             4: \"buena\",\n",
    "             4.5: \"buena\",\n",
    "             5: \"buena\"    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ratings[\"rating_label\"] = data_ratings.rating.map(etiquetas)\n",
    "data_ratings.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nota: esto ya sabíamos resolverlo usando máscaras booleanas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Reemplazar valores\n",
    "\n",
    "El método `replace` ofrece varias formas de efectuar reemplazos sobre una serie de Pandas:\n",
    "\n",
    "* Un valor viejo por un valor nuevo.\n",
    "    \n",
    "* Una lista de valores viejos por un valor nuevo.\n",
    "    \n",
    "* Una lista de valores viejos por una lista de valores nuevos.\n",
    "    \n",
    "* Un diccionario que mapee valores nuevos y viejos.\n",
    "\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.replace.html\n",
    "\n",
    "**4.a - Una lista de valores viejos por un valor nuevo** \n",
    "\n",
    "Veamos cuáles son los tags que están asignados a una única película. \n",
    "\n",
    "Reemplacemos ese valor por \"tag_que_no_funciona\" y eliminemos registros duplicados considerando los campos \"userId\",  \"movieId\", \"tag\".\n",
    "\n",
    "Ayuda: `value_counts`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts = data_tags.tag.value_counts()\n",
    "tag_counts_1_mask = tag_counts == 1\n",
    "tags_counts_1 = tag_counts.loc[tag_counts_1_mask]\n",
    "print(len(tag_counts))\n",
    "print(len(tags_counts_1))\n",
    "tags_counts_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tags_frecuentes =  data_tags.replace(tags_counts_1.index, \"tag_que_no_funciona\")\n",
    "data_tags_frecuentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tags_frecuentes_nodup = data_tags_frecuentes.drop_duplicates(subset = [\"userId\", \"movieId\", \"tag\"], keep = \"first\")\n",
    "print(data_tags_frecuentes_nodup.shape)\n",
    "print(data_tags_frecuentes.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.b - Una lista de valores viejos por una lista de valores nuevos**\n",
    "\n",
    "Reemplacemos cada valor de tag, por la primera palabra que lo compone.\n",
    "\n",
    "Para eso, creamos una serie con valores únicos con el valor del campo tag. \n",
    "\n",
    "Contruimos otra instancia de Series donde cada elemento sea la primera palabra del objeto Series anterior. Ayuda: listas por comprensión y `split`\n",
    "\n",
    "Usamos replace para campiar el valor de cada tag por su primera palabra.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_unique = data_tags.tag.unique()\n",
    "#print(tags_unique)\n",
    "print(len(tags_unique))\n",
    "tags_primera_palabra = [x.split()[0] for x in tags_unique]\n",
    "#print(tags_primera_palabra)\n",
    "print(len(tags_primera_palabra))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tags_resumen = data_tags.replace(tags_unique, tags_primera_palabra)\n",
    "print(data_tags.head(10))\n",
    "print(data_tags_resumen.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.c - Un diccionario que mapee valores nuevos y viejos**\n",
    "\n",
    "Reemplacemos los valores de tags \n",
    "* \"Al Pacino\" por \"Pacino\"\n",
    "* \"Leonardo DiCaprio\" por \"DiCaprio\"\n",
    "* \"Tom Hanks\" por \"Hanks\"\n",
    "* \"Martin Scorsese\" por \"Scorsese\"\n",
    "\n",
    "Contemos cuantas veces aparecen cada uno de los valores a reemplazar, y cuántas los valores de reemplazo. Ayuda: `value_counts`\n",
    "\n",
    "Construyamos un diccionario con este mapeo y usemos el método `replace`\n",
    "\n",
    "Volvamos a contar cuántas veces aparecen cada uno de los valores a reemplazar, y cuántas los valores de reemplazo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts = data_tags.tag.value_counts()\n",
    "print(tag_counts[\"Al Pacino\"])\n",
    "print(tag_counts[\"Leonardo DiCaprio\"])\n",
    "print(tag_counts[\"Tom Hanks\"])\n",
    "print(tag_counts[\"Martin Scorsese\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pacino\" in tag_counts.keys())\n",
    "print(\"DiCaprio\" in tag_counts.keys())\n",
    "print(\"Hanks\" in tag_counts.keys())\n",
    "print(\"Scorsese\" in tag_counts.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement = {\n",
    "    \"Al Pacino\": \"Pacino\", \n",
    "    \"Leonardo DiCaprio\": \"DiCaprio\",\n",
    "    \"Tom Hanks\": \"Hanks\",\n",
    "    \"Martin Scorsese\": \"Scorsese\"\n",
    "}\n",
    "\n",
    "data_tags_dict_replacement = data_tags.replace(replacement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_counts_replacement = data_tags_dict_replacement.tag.value_counts()\n",
    "print(tag_counts_replacement[\"Pacino\"])\n",
    "print(tag_counts_replacement[\"DiCaprio\"])\n",
    "print(tag_counts_replacement[\"Hanks\"])\n",
    "print(tag_counts_replacement[\"Scorsese\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Al Pacino\" in tag_counts_replacement.keys())\n",
    "print(\"Leonardo DiCaprio\" in tag_counts_replacement.keys())\n",
    "print(\"Tom Hanks\" in tag_counts_replacement.keys())\n",
    "print(\"Martin Scorsese\" in tag_counts_replacement.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Discretizar variables\n",
    "\n",
    "Vamos a volver a resolver el Ejercicio 3 usando el método `cut`\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html\n",
    "\n",
    "Defino los valores de corte:\n",
    "\n",
    "* mala, para puntajes menores a 3;\n",
    "\n",
    "* regular, para mayor igual a 3 y  menor que 4;\n",
    "\n",
    "* buena para puntaje mayor o igual que 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# valores de corte:\n",
    "bins_rating = [0, 3, 4, 5.1]\n",
    "labels_rating = [\"mala\", \"regular\", \"buena\"]\n",
    "\n",
    "# Obtengo una lista de intervalos\n",
    "# right=False indice que el extremo derecho del intervalo no está incluído en la categoría\n",
    "categories = pd.cut(data_ratings.rating, bins_rating, labels = labels_rating, right=False)\n",
    "\n",
    "data_ratings[\"rating_label_cut\"] = categories\n",
    "data_ratings.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 - Detectar y filtrar outliers\n",
    "\n",
    "No existe un criterio que sea válido en todos los casos para identificar los outliers. El criterio de mayor que el tercer cuartil más 1.5 veces el rango intercuartil o menor que el primer cuartil menos 1.5 veces el rango intercuartil (Q3 - Q1) surge de la distribución normal. En esa distribución el 99.7% de la población se encuentra en el rango definido por la media (poblacional) más menos 3 veces el desvío estándar (poblacional)\n",
    "\n",
    "**Queremos ver cuáles son las películas que son outliers en cantidad de calificaciones.**\n",
    "\n",
    "**6.a** Usando data_ratings eliminamos duplicados considerando las columnas \"userId\", \"movieId\". Esto lo hacemos para contar sólo una vez los votos de un usuario a una película.\n",
    "\n",
    "**6.b** Sobre el DataFrame obtenido en el paso anterior, hacemos count agrupado por película. Esto nos da como resultado una instancia de Series que asignamos a la variable movie_votes_count.\n",
    "\n",
    "**6.c** Calculemos los cuartilos de los valores de movie_votes_count y los valores que usaremos de umbral para determinar outliers.\n",
    "(Ayuda: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.quantile.html)\n",
    "\n",
    "**6.d** Filtremos los datos de movie_votes_count excluyendo los outliers. \n",
    "\n",
    "**6.e** Comparemos movie_votes_count antes y después del filtro con:\n",
    "* el método `describe`\n",
    "* boxplots de seaborn\n",
    "\n",
    "**6.f** Adicional: Miremos cuáles son los títulos de las cinco películas más votadas que son outliers de cantidad de calificaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.a\n",
    "\n",
    "data_ratings_nodup = data_ratings.drop_duplicates(subset = [\"userId\", \"movieId\"], keep = \"first\")\n",
    "\n",
    "#6.b\n",
    "movie_votes_count = data_ratings_nodup.groupby(\"movieId\")[\"userId\"].count()\n",
    "\n",
    "#6.c\n",
    "q1 = movie_votes_count.quantile(0.25)\n",
    "print(q1)\n",
    "q2 = movie_votes_count.quantile(0.5)\n",
    "print(q2)\n",
    "q3 = movie_votes_count.quantile(0.75)\n",
    "print(q3)\n",
    "\n",
    "\n",
    "iqr = (q3 - q1) * 1.5\n",
    "\n",
    "up_threshold = q3 + iqr\n",
    "low_threshold = q1 - iqr\n",
    "\n",
    "print(up_threshold)\n",
    "print(low_threshold)\n",
    "\n",
    "#6.d\n",
    "outlier_mask_up = movie_votes_count > up_threshold\n",
    "outlier_mask_down = movie_votes_count < low_threshold\n",
    "outlier_mask = np.logical_or(outlier_mask_up, outlier_mask_down)\n",
    "not_outliers = np.logical_not(outlier_mask)\n",
    "\n",
    "outliers = movie_votes_count[outlier_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.e\n",
    "movie_votes_count_filtered = movie_votes_count[not_outliers]\n",
    "movie_votes_count_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_votes_count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.boxplot(x=movie_votes_count.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=movie_votes_count_filtered.values);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6.f\n",
    "\n",
    "outliers_sort = np.sort(outliers.values)[::-1]\n",
    "print(\"cantidad de votos ordenados de mayor a menor: \", outliers_sort)\n",
    "\n",
    "top_5 = outliers_sort[0:5]\n",
    "print(\"cantidad de votos máximos: \", top_5)\n",
    "\n",
    "top_5_outliers_mask = outliers.apply(lambda x: x in top_5)\n",
    "top_5_outliers_movieId = outliers.loc[top_5_outliers_mask].index\n",
    "print(\"ids de las peliculas en el top 5 de votos\", top_5_outliers_movieId)\n",
    "\n",
    "top_5_movieId_mask = data_movies.movieId.apply(lambda x: x in top_5_outliers_movieId)\n",
    "data_movies.loc[top_5_movieId_mask, \"title\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7 - Variables categóricas y dummies\n",
    "\n",
    "**7.a** Usando el método `get_dummies` con `drop_first = True` agreguemos al DataFrame data_ratings variables dummies que representen las categorias de rating_label\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\n",
    "\n",
    "\n",
    "**7.b** Comparemos las variables dummies generadas en el punto anterior con las que se generan usando `drop_first = False`. ¿Cuál es la diferencia? ¿Representan el mismo conjunto de valores posibles?\n",
    "\n",
    "**7.c** Adicional: Cambienos las categorias que se muestran como resultado de `get_dummies` con `drop_first = True`. Ayuda: https://pandas.pydata.org/pandas-docs/stable/user_guide/categorical.html#categoricaldtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.a\n",
    "\n",
    "dummies_rating_label = pd.get_dummies(data_ratings.rating_label, prefix='rating_label', drop_first=True)\n",
    "\n",
    "# agregamos las columnas dummies\n",
    "data_ratings_with_dummy = data_ratings.join(dummies_rating_label)\n",
    "\n",
    "# quitamos la columna rating_label que ahora queda representada por las dummies\n",
    "result = data_ratings_with_dummy.drop(labels = [\"rating_label\"], axis=\"columns\")\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.b\n",
    "\n",
    "dummies_rating_label = pd.get_dummies(data_ratings.rating_label, prefix='rating_label', drop_first=False)\n",
    "dummies_rating_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta segunda solución (7.b), tenemos una columna para cada categoría de los valores originales. \n",
    "\n",
    "Los valores representados son exactamente los mismos que había en la columna original (como en las solución 7.a), pero una de las columnas es redundante porque se puede determinar su valor partiendo de los valores de las otras dos.\n",
    "\n",
    "Las dos soluciones representan todas la categorias posibles de la variable original. \n",
    "\n",
    "Observemos que los valores (0,0,0), (0,1,1), (1,1,0), (1,0,1), (1,1) no representan una categoría en la variable original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.c\n",
    "\n",
    "from pandas.api.types import CategoricalDtype\n",
    "    \n",
    "cat_type = CategoricalDtype(categories=[\"mala\", \"regular\", \"buena\"], ordered=True)\n",
    "\n",
    "labels_cat = data_ratings.rating_label.astype(cat_type)\n",
    "\n",
    "pd.get_dummies(labels_cat, prefix='rating_label', drop_first=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
