{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "    \n",
    "    ! mkdir -p ../Data\n",
    "    # los que usan colab deben modificar el token de esta url:\n",
    "    ! wget -O ../Data/ab_data.csv https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_students_2020/master/M2/CLASE_11_Estadistica_Inferencial/Data/ab_data.csv?token=AA4GFHLD7JL37UB2Z4P6O7C6YV4FE\n",
    "    ! wget -O ../Data/klout-scores.csv https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_students_2020/master/M2/CLASE_11_Estadistica_Inferencial/Data/klout-scores.csv?token=AA4GFHKHCDGQ3VHY6XMID6K6YV4TQ\n",
    "    ! wget -O ../Data/wildlife.csv https://raw.githubusercontent.com/Digital-House-DATA/ds_blend_students_2020/master/M2/CLASE_11_Estadistica_Inferencial/Data/wildlife.csv?token=AA4GFHM5EEHYTE5ARKPTUHS6YV4WM    \n",
    "        \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import math\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Intervalos de Confianza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Utilizamos una muestra aleatoria de puntajes de influencia de redes sociales del servicio http://klout.com. \n",
    "\n",
    "Klout era un sitio web y una aplicación móvil que utilizaba análisis de redes sociales para calificar usuarios de acuerdo con su influencia social en línea. \n",
    "\n",
    "El sitio calculaba un \"Klout Score\", que era un valor numérico entre 1 y 100 donde puntuaciones más altas correspondian a una mayor \"influencia social\" en línea.\n",
    "\n",
    "De una población de más de 620 millones de puntajes obtuvimos una muestra de tamaño 1048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/klout-scores.csv', header=None, names=['scores'])\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratorio\n",
    "\n",
    "Grafiquemos los valores de score que leimos en la variable data, y observemos que hay dos picos. Uno corresponde a los consumidores y el otro a los influencers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=sns.distplot(data.scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intervalo de confianza\n",
    "\n",
    "Si queremos estimar un parámetro poblacional (media, proporción, desvío estandar) a partir de un estadístico muestral, no podemos estar seguros del resultado pero podemos dar algún nivel de confianza a nuestra predicción por medio de un intervalo de confianza (CI).\n",
    "\n",
    "|   |media|proporción|desvío estandar|   |\n",
    "|---|:---:|:---:|:---:|---|\n",
    "|población|$\\mu$|$p$|$\\sigma$|parámetros|\n",
    "|muestra|$\\bar{x}$|$\\hat{p}$|$s$|estadísticos|\n",
    "\n",
    "Calculemos un intervalo de confianza del 95% para la media muestral del dataset Klout Scores.\n",
    "\n",
    "Para muestras grandes, podemos resolver esta ecuación con un nivel de alfa de $\\alpha=.05$\n",
    "\n",
    "$$\\bar{x}+z_{\\alpha/2}\\cdot\\frac{\\sigma}{\\sqrt{n}}\\lt\\mu_{estimator}\\lt\\bar{x}-z_{\\alpha/2}\\cdot\\frac{\\sigma}{\\sqrt{n}}$$ \n",
    "\n",
    "Calculemos estos valores para nuestros datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Media muestral:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klout_xbar = data.scores.mean()\n",
    "klout_xbar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Desvío estandar de la muestra\n",
    "\n",
    "Como nuestar muestra es grande (de tamaño mayor que 30) podemos usar el desvío estandar muestral como aproximación de sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klout_sd = data.scores.std()\n",
    "klout_sd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Error estandar de la muestra:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need the standard error to calculate the bounds\n",
    "n = data.shape[0]\n",
    "klout_se = klout_sd / math.sqrt(n)\n",
    "klout_se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### z-scores:\n",
    "\n",
    "Calculamos los z-score para poder calcular los límites inferior y superior del intervalo de confianza.\n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
    "\n",
    "**CDF**: Cumulative Distribution Function usamos `stats.cdf`\n",
    "\n",
    "**ppf**: Percent Point Function (Inverse of CDF) usamos `stats.ppf`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_value = stats.norm.ppf(alpha / 2) * (-1)\n",
    "critical_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una forma alternativa para obtener el intervalo de valores críticos es usar \n",
    "\n",
    "`interval(alpha, loc=0, scale=1)` que devuelve los límites del rango que contiene alfa-porciento de la distribución\n",
    "\n",
    "Observemos que el argumento alfa de esta función **no** es el valor de alfa que definimos arriba, sino 1 - ese valor. \n",
    "\n",
    "Llamaremos nivel de confianza (confidence coefficient) al valor del argumento alpha de la función interval.\n",
    "\n",
    "https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.stats.norm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_coef = 1 - alpha\n",
    "zscore_interval = stats.norm.interval(alpha=confidence_coef)\n",
    "zscore_interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculamos los límites inferior y superior del intervalo de confianza para la media de Klout Score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klout_CI_mean_lower = klout_xbar - critical_value * klout_se\n",
    "klout_CI_mean_upper = klout_xbar + critical_value * klout_se\n",
    "klout_CI_mean_lower, klout_CI_mean_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ¿Qué significa este resultado?\n",
    "\n",
    "Un intervalo de confianza trata de capturar la media de la población real de una muestra declarando un intervalo de confianza. Esto significa que el 95% de los intervalos que calculemos a partir de muestras independientes atrapan el verdadero valor de la media poblacional.\n",
    "\n",
    "Klout.com afirma que su puntaje promedio es 40, por lo que no obtuvimos el parámetro promedio de población real (el valor que obtuvimos es 37.7). Dado que nuestros cálculos parecen ser correctos, esto podría significar que:\n",
    "* Tal vez nuestra media muestral está muy por debajo de la media poblacional. Tengamos en cuenta que solo tenemos un 95% de confianza.\n",
    "* Quizás la comunicación de Klout sobre el puntaje promedio se simplifica a un valor fácil de recordar de 40.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Efecto del tamaño de muestra\n",
    "\n",
    "El tamaño de la muestra afecta los límites del intervalo de confianza. Cuanto más pequeña es la muestra, menos confianza tenemos, por lo tanto, más amplio es el intervalo de confianza. Probemos esto con una muestra aleatoria de los datos de Klout Score de n = 50.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 50\n",
    "random_generator = np.random.default_rng()\n",
    "index_sample = random_generator.choice(data.index, size = n_sample)\n",
    "data_sample = data.loc[index_sample]\n",
    "data_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graficamos la distribución de la muestra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=sns.distplot(data_sample.scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculamos el intervalo de confianza:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# media muestral\n",
    "klout_sample_xbar = data_sample.scores.mean()\n",
    "klout_sample_xbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# desvío estandar\n",
    "klout_sample_sd = data_sample.scores.std()\n",
    "klout_sample_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# error estandar\n",
    "n_sample = data_sample.shape[0]\n",
    "klout_sample_se = klout_sample_sd / math.sqrt(n_sample)\n",
    "klout_sample_se"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-score\n",
    "alpha = 0.05\n",
    "sample_critical_value = stats.norm.ppf(alpha / 2) * (-1)\n",
    "sample_critical_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "klout_sample_CI_mean_lower = klout_sample_xbar - sample_critical_value * klout_sample_se\n",
    "klout_sample_CI_mean_upper = klout_sample_xbar + sample_critical_value * klout_sample_se\n",
    "klout_sample_CI_mean_lower, klout_sample_CI_mean_upper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con este tamaño de muestra, estamos 95% seguros de que atrapamos el verdadero valor de la muestra en el intervalo klout_sample_CI_mean_lower, klout_sample_CI_mean_upper. \n",
    "\n",
    "Aunque este intervalo de confianza capta el parámetro medio, también tiene un rango mucho más grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Hacer una función que dados\n",
    "* una población como una instancia de Series \n",
    "* un tamaño de muestra \n",
    "* un valor de alfa\n",
    "* un valor de sigma\n",
    "Calcule el tamaño del intervarlo de confianza para la media con ese alfa, como máximo - mínimo.\n",
    "\n",
    "Para 20 valores de tamaño de muestra, grafiquemos el tam del intervalo vs tamaño de muestra\n",
    "\n",
    "Ayuda: https://numpy.org/doc/stable/reference/generated/numpy.linspace.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confidence_interval_size(data, sample_size, alpha, sigma):    \n",
    "    random_generator = np.random.default_rng()\n",
    "    sample_data = random_generator.choice(data, size = sample_size,  replace=True)    \n",
    "    sample_mean = np.mean(sample_data)\n",
    "    z_critico = stats.norm.ppf(alpha/2)\n",
    "    n = len(sample_data)\n",
    "    ic_high = sample_mean - z_critico * sigma / math.sqrt(n)\n",
    "    ic_low = sample_mean + z_critico * sigma / math.sqrt(n)\n",
    "    result = ic_high - ic_low\n",
    "    return result\n",
    "\n",
    "sample_sizes = np.linspace(start=30, stop=200, num=20).astype(int)\n",
    "\n",
    "ic_sizes = []\n",
    "\n",
    "data_population = data.scores\n",
    "sigma = klout_sd\n",
    "\n",
    "for sample_size in sample_sizes:\n",
    "    ic_size = confidence_interval_size(data_population, sample_size, alpha, sigma)\n",
    "    ic_sizes.append(ic_size)\n",
    "\n",
    "result = dict(zip(sample_sizes, ic_sizes))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x=list(result.keys()), y=list(result.values()), )\n",
    "ax.set(xlabel='sample sizes', ylabel='ci sizes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Test de Hipótesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "El dataset que usamos en esta parte contiene reportes de  [Federal Aviation Administration Wildlife Strike Database](http://wildlife.faa.gov/database.aspx) correspondientes a los años 2012 y 2013 en el estado de California, USA.\n",
    "\n",
    "Usaremos los datos diarios de frecuencia de incidentes de golpes a fauna silvestre.\n",
    "\n",
    "### Leemos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data from a csv file. \n",
    "data_location = \"../Data/wildlife.csv\"\n",
    "data = pd.read_csv(data_location)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: Preparación de los datos\n",
    "\n",
    "Construyamos un dataset que tenga como columnas\n",
    "\n",
    "* la fecha del incidente, de tipo datetime\n",
    "\n",
    "Ayuda: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.to_datetime.html\n",
    "\n",
    "* la cantidad de incidentes en esa fecha, de tipo int \n",
    "\n",
    "Ayuda: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.INCIDENT_DATE = pd.to_datetime(data.INCIDENT_DATE)\n",
    "data_fecha = data[['INCIDENT_DATE']]\n",
    "data_fecha_count = data_fecha.groupby('INCIDENT_DATE')['INCIDENT_DATE'].size()\n",
    "data_fecha_count.name = \"INCIDENT_COUNT\"\n",
    "data_fecha_count = data_fecha_count.reset_index()\n",
    "data_fecha_count.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: Preparación de los datos - continuación\n",
    "\n",
    "Queremos que el DataFrame que creamos en el paso anterior tenga un registro por cada día del año 2012 y 2013.\n",
    "\n",
    "Para eso vamos a: \n",
    "\n",
    "1) Asignar el valor del campo INCIDENT_DATE como índice del DataFrame construído en el punto anterior \n",
    "\n",
    "2) Crear un nuevo DataFrame que tenga sólo un índice y ninguna columna, que sea todas las fechas existentes durante los años 2012 y 2013 \n",
    "\n",
    "Ayuda: `pandas.date_range` https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html\n",
    "\n",
    "3) Hacer un join entre los DataFrame 1) y 2). Con esto vamos a conseguir que en el DataFrame resultado haya valores null en el campo INCIDENT_COUNT para las fechas que no estaban en el DataFrame resultado del ejercicio anterior.\n",
    "\n",
    "Ayuda: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.join.html\n",
    "\n",
    "4) Por último, completamos los valores nulos de INCIDENT_COUNT en el nuevo DataFrame con el valor cero\n",
    "\n",
    "Ayuda: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.fillna.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fecha_count.index = data_fecha_count.INCIDENT_DATE\n",
    "data_fecha_count = data_fecha_count.drop(['INCIDENT_DATE'], axis=1)\n",
    "data_fecha_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_from = datetime.date(day=1, month=1, year=2012)\n",
    "date_to = datetime.date(day=31, month=12, year=2013)\n",
    "fechas_2012_2013 = pd.date_range(date_from, date_to, freq='D')\n",
    "\n",
    "dates_df = pd.DataFrame(index = fechas_2012_2013)\n",
    "dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012_2013 = data_fecha_count.join(dates_df, how='right')\n",
    "data_2012_2013.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012_2013.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012_2013.fillna(value = 0, axis= 1, inplace=True)\n",
    "data_2012_2013.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: Exploratorio\n",
    "\n",
    "Usemos un gráficos de barras para representar los valores de frecuencia de accidentes en los años 2012 y 2013 (por separado)\n",
    "\n",
    "Para eso, agregamos al DataFrame una columna de tipo int que indique el mes que corresponde al valor de index de cada registro.\n",
    "\n",
    "Y usemos los valores de esta nueva columna como eje x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012_2013[\"plot_month\"] = [x.month for x in data_2012_2013.index]\n",
    "data_2012_2013.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# magia!\n",
    "# https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#selection-by-label\n",
    "data_2012 = data_2012_2013['2012']\n",
    "data_2013 = data_2012_2013['2013']\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True)\n",
    "sns.barplot(x=data_2012.plot_month, y= data_2012.INCIDENT_COUNT, ax=ax1)\n",
    "sns.barplot(x=data_2013.plot_month, y = data_2013.INCIDENT_COUNT, ax=ax2)\n",
    "ax1.set_title('Wildlife Strike Incidents 2012')\n",
    "ax2.set_title('Wildlife Strike Incidents 2013')\n",
    "ax1.set_xlabel('')\n",
    "ax2.set_xlabel('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio: Test de hipótesis\n",
    "\n",
    "Asumamos que la Federal Aviation Administration lanzó en el 2013 un nuevo programa de prevención de incidentes con fauna silvestre.\n",
    "\n",
    "Queremos saber si hay una baja significativa en el número diario de incidentes del año 2013 respecto del 2012.\n",
    "\n",
    "Elegimos como nivel de significación (alfa) 0.05\n",
    "\n",
    "Una probabilidad menor a 0.05 rechaza la hipótesis nula.\n",
    "\n",
    "La hipótesis nula es que la media de incidentes del 2012 es la media poblacional y es igual a la media poblacional de incidentes del 2013.\n",
    "\n",
    "La hipótesis alternativa es que la media de incidentes del 2013 es menor que la del 2012.\n",
    "\n",
    "|Hypothesis|$\\alpha = .05$|   |\n",
    "|---|:---:|:---|\n",
    "|Null|$H_0:$|$\\mu = \\bar{x}_{2013}$|\n",
    "|Alternative|$H_a:$|$\\mu \\gt \\bar{x}_{2013} $|\n",
    "\n",
    "Calculemos la media de incidentes y desvío para los años 2012 y 2013"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xbar_2012 = data_2012.INCIDENT_COUNT.mean()\n",
    "sd_2012 = data_2012.INCIDENT_COUNT.std()\n",
    "print(xbar_2012, sd_2012)\n",
    "\n",
    "xbar_2013 = data_2013.INCIDENT_COUNT.mean()\n",
    "sd_2013 = data_2013.INCIDENT_COUNT.std()\n",
    "print(xbar_2013, sd_2013)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notamos que la media de incidentes del 2013 es un poco menor que la del 2102.\n",
    "\n",
    "Queremos saber si esta diferencia se debe a la variación normal de estos dato, es decir que la diferencia se puede adjudicar al azar. \n",
    "\n",
    "Para eso, calculemos el z-score y usemos un nivel de significación 0.05\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = xbar_2012\n",
    "sigma = sd_2012\n",
    "n = data_2013.shape[0]\n",
    "se = sigma / math.sqrt(n)\n",
    "zscore = (xbar_2013 - mu) / se\n",
    "zscore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculamos valores críticos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = .05\n",
    "critical_value = stats.norm.ppf(alpha)\n",
    "critical_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafiquemos datos con distribución normal, la región de rechazo, y el valor de zscore obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the normal distribution\n",
    "samples = 100\n",
    "x_plot = np.linspace(-3.5, 3.5, samples)\n",
    "y_plot = stats.norm.pdf(x_plot, 0, 1)\n",
    "plt.plot(x_plot, y_plot)\n",
    "\n",
    "# Plot the critical region\n",
    "x_crit = np.linspace(-3.5, critical_value, samples)\n",
    "y_crit = stats.norm.pdf(x_crit, 0, 1)\n",
    "# colorea la region de rechazo de H0:\n",
    "plt.fill_between(x_crit,  y_crit, alpha=.5)\n",
    "\n",
    "# Plot the z score, linea naranja:\n",
    "plt.plot([zscore, zscore], [0, stats.norm.pdf(zscore)])\n",
    "\n",
    "# Show legend\n",
    "plt.legend(['critical region', 'z score'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como zscore no es menor que critical_value, no podemos rechazar H0.\n",
    "\n",
    "Esto indica que podemos obtener por azar una media muestral con ese valor de la misma población real.\n",
    "\n",
    "En otras palabras, no hay diferencia significativa en los promedios de incidentes en 2012 y 2013.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "Los datos corresponden a las visitas de usuarios a un sitio web.\n",
    "\n",
    "Este sitio tiene dos versiones de la landing: old_page y new_page\n",
    "\n",
    "El campo \"converted\" indica si un usuario hizo click o no, idicados con 1 o 0 respectivamente, en la pagina que vio.\n",
    "\n",
    "El objetivo es determinar si la nueva versión de la página tiene más proporción de clicks que la vieja.\n",
    "\n",
    "https://www.kaggle.com/zhangluyuan/ab-testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_location = \"../Data/ab_data.csv\"\n",
    "data = pd.read_csv(data_location, sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos que eliminar todos los registros que sean \n",
    "* 'control' y 'new_page' \n",
    "* 'treatment' y 'old_page'\n",
    "\n",
    "Miremos cuántos no están en esas condiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_mask = data.group == 'control'\n",
    "treatment_mask = data.group == 'treatment'\n",
    "new_mask = data.landing_page == 'new_page'\n",
    "old_mask = data.landing_page == 'old_page'\n",
    "control_new_mask = np.logical_and(control_mask, new_mask)\n",
    "treatment_old_mask = np.logical_and(treatment_mask, old_mask)\n",
    "print(control_new_mask.sum(), treatment_old_mask.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminemos los registros detectados en el paso anterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_new_index_to_drop = data.index[control_new_mask]\n",
    "data_clean_1 = data.drop(index = control_new_index_to_drop, axis=0)\n",
    "data_clean_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_old_index_to_drop = data.index[treatment_old_mask]\n",
    "data_clean_2 = data_clean_1.drop(index = treatment_old_index_to_drop, axis=0)\n",
    "data_clean_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminemos los registros duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ab = data_clean_2.drop_duplicates(subset ='user_id',keep ='first', inplace = False)\n",
    "data_ab.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la probabilidad de conversion independiente de la página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converted_mask = data_ab.converted == 1\n",
    "converted_mask.sum() / data_ab.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la probabilidad de convertir si el usuario ve la página nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask = data_ab.landing_page == 'new_page'\n",
    "new_converted_mask = np.logical_and(new_mask, data_ab.converted == 1)\n",
    "new_converted_mask.sum() / new_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la probabilidad de convertir si si el usuario ve la página vieja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_mask = data_ab.landing_page == 'old_page'\n",
    "old_converted_mask = np.logical_and(old_mask, data_ab.converted == 1)\n",
    "old_converted_mask.sum() / old_mask.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la probabilidad de ver la página nueva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_mask.sum() / data_ab.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que calcula los estimadores de los parámetros de una distribución de Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimated_parameters(N, n):\n",
    "    p = n/N\n",
    "    sigma = math.sqrt(p*(1-p)/N)\n",
    "    return p, sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una función que calcula el estadístico de un A/B Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_b_test_statistic(N_A,n_A,N_B,n_B):\n",
    "    p_A, sigma_A = estimated_parameters(N_A, n_A)\n",
    "    p_B, sigma_B = estimated_parameters(N_B, n_B)\n",
    "    return (p_B - p_A)/math.sqrt(sigma_A**2 + sigma_B**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos el valor del estadístico definido por esta función y los valores críticos y p-value para decidir si rechazamos H0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_old_page_mask = data_ab.landing_page == \"old_page\"\n",
    "control_old_page = data_ab.loc[control_old_page_mask, :]\n",
    "N_control_old = control_old_page.shape[0]\n",
    "n_control_old = control_old_page.converted.sum()\n",
    "print(N_control_old, n_control_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "treatment_new_page_mask = data_ab.landing_page == \"new_page\"\n",
    "treatment_new_page = data_ab.loc[treatment_new_page_mask, :]\n",
    "N_treatment_new = treatment_new_page.shape[0]\n",
    "n_treatment_new = treatment_new_page.converted.sum()\n",
    "print(N_treatment_new, n_treatment_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H0: p_new = p_old\n",
    "\n",
    "H1: p_new != p_old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_parameters(N_control_old, n_control_old)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces para la versión vieja, el valor estimado de p es 0.120 y sigma 0.0008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimated_parameters(N_treatment_new, n_treatment_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces para la versión nueva, el valor estimado de p es 0.118 y sigma 0.0008\n",
    "\n",
    "No parece haber diferencia entre los resultados de ambas versiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definimos un nivel de significación del 5%. Vamos a hacer un test a dos colas:\n",
    "alpha=0.05\n",
    "z_crit = np.abs(stats.norm.ppf(alpha/2))\n",
    "z_crit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entonces los valores críticos, que definen las regiones de rechazo, son -1.96 y 1.96\n",
    "\n",
    "Calculamos el estadítico para el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_est = a_b_test_statistic(N_treatment_new,n_treatment_new,N_control_old,n_control_old)\n",
    "z_est"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor del estadítico está fuera de la región de rechazo, porque no verifica z_est < -1.96, ni z_est > 1.96. Por lo tanto no rechazamos H0.\n",
    "\n",
    "Veamos qué concluimos usando p-value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_value = 2 * stats.norm.cdf((-1) * z_est)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El valor de p_value es 0.18.\n",
    "\n",
    "Rechazamos H0 cuando p-value es menor que el nvel de significación del test (0.05 para este ejercicio)\n",
    "\n",
    "Como 0.18 no es menor que 0.05 (el nivel de significación), entonces no rechazamos H0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus track**:\n",
    "    \n",
    "Más adelante en este curso vamos ver la biblioteca statsmodels, que ahora vamos a mencionar porque nos permite calcular z-score y p-value para nuestro problema, y compararlo con los resultados que obtuvimos con nuestras funciones.\n",
    "\n",
    "https://www.statsmodels.org/0.6.1/generated/statsmodels.stats.proportion.proportions_ztest.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_score, p_value = sm.stats.proportions_ztest([n_control_old, n_treatment_new], [N_control_old, N_treatment_new], \n",
    "                                              alternative='two-sided')\n",
    "z_score, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "\n",
    "Intervalos de Confianza\n",
    "https://github.com/leonvanbokhorst/NoteBooks-Statistics-and-MachineLearning/blob/master/0013%20Confidence%20Interval%20of%20a%20Klout%20Score%20sample.ipynb\n",
    "\n",
    "Test de Hipótesis\n",
    "https://github.com/leonvanbokhorst/NoteBooks-Statistics-and-MachineLearning/blob/master/0014%20Hypothesis%20Testing%20with%20Bird%20Strike%20Incidents.ipynb\n",
    "\n",
    "A/B testing\n",
    "https://www.kaggle.com/shweta112/a-b-testing-analysis\n",
    "\n",
    "A/B testing, un ejemplo (un poco más difícil) para analizar \n",
    "\n",
    "https://www.kaggle.com/tammyrotem/ab-tests-with-python\n",
    "    \n",
    "https://github.com/baumanab/udacity_ABTesting#summary\n",
    "        \n",
    "https://github.com/TammyRotem/A-B_Tests_with_Python/blob/master/AB_Testing_with_Python.ipynb        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
