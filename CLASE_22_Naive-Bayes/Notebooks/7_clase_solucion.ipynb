{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "        \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "Vamos a construir un clasificador que intente predecir si una persona ganará más de US$ 50.000 por año \n",
    "\n",
    "Hicimos preparación de los datos en la práctica de checkpoint. Los datasets resultado de esa práctica son el input de ésta. Si no la hicieron, comiencen con esa y después sigan en esta notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "https://archive.ics.uci.edu/ml/datasets/Adult\n",
    "\n",
    "Los datos corresponden a un censo de 1994.\n",
    "\n",
    "Los campos son\n",
    "\n",
    "age: continuous.\n",
    "\n",
    "workclass: Private, Self-emp-not-inc, Self-emp-inc, Federal-gov, Local-gov, State-gov, Without-pay, Never-worked.\n",
    "\n",
    "fnlwgt: continuous.\n",
    "\n",
    "education: Bachelors, Some-college, 11th, HS-grad, Prof-school, Assoc-acdm, Assoc-voc, 9th, 7th-8th, 12th, Masters, 1st-4th, 10th, Doctorate, 5th-6th, Preschool.\n",
    "\n",
    "education-num: continuous.\n",
    "\n",
    "marital-status: Married-civ-spouse, Divorced, Never-married, Separated, Widowed, Married-spouse-absent, Married-AF-spouse.\n",
    "\n",
    "occupation: Tech-support, Craft-repair, Other-service, Sales, Exec-managerial, Prof-specialty, Handlers-cleaners, Machine-\n",
    "\n",
    "op-inspct, Adm-clerical, Farming-fishing, Transport-moving, Priv-house-serv, Protective-serv, Armed-Forces.\n",
    "\n",
    "relationship: Wife, Own-child, Husband, Not-in-family, Other-relative, Unmarried.\n",
    "\n",
    "race: White, Asian-Pac-Islander, Amer-Indian-Eskimo, Other, Black.\n",
    "\n",
    "sex: Female, Male.\n",
    "\n",
    "capital-gain: continuous.\n",
    "\n",
    "capital-loss: continuous.\n",
    "\n",
    "hours-per-week: continuous.\n",
    "\n",
    "native-country: United-States, Cambodia, England, Puerto-Rico, Canada, Germany, Outlying-US(Guam-USVI-etc), India, Japan, \n",
    "Greece, South, China, Cuba, Iran, Honduras, Philippines, Italy, Poland, Jamaica, Vietnam, Mexico, Portugal, Ireland, France, Dominican-Republic, Laos, Ecuador, Taiwan, Haiti, Columbia, Hungary, Guatemala, Nicaragua, Scotland, Thailand, Yugoslavia, El-Salvador, Trinadad&Tobago, Peru, Hong, Holand-Netherlands.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train_location = '../Data/adult_train.csv'\n",
    "data_test_location = '../Data/adult_test.csv'\n",
    "\n",
    "data_train = pd.read_csv(data_train_location, sep='\\t', low_memory=False)\n",
    "data_test = pd.read_csv(data_test_location, sep='\\t', low_memory=False)\n",
    "\n",
    "data_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 - Freatures Target\n",
    "\n",
    "Sabiendo que 'income' es el nombre de la columna target, construyamos la matriz de features y el vector target para los conjuntos de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop('income', axis = 1)\n",
    "X_test = data_test.drop('income', axis = 1)\n",
    "\n",
    "Y_train = data_train.income\n",
    "Y_test = data_test.income\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Training\n",
    "\n",
    "Instanciemos y entrenemos uno modelo naive bayes gaussiano.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnb = GaussianNB()\n",
    "\n",
    "gnb.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Predict\n",
    "\n",
    "Usemos el modelo entrenado en el ejercicio 2 para predecir la etiqueta de los datos de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = gnb.predict(X_test)\n",
    "\n",
    "Y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Performance\n",
    "\n",
    "Para los datos de test, calculemos accuracy:\n",
    "\n",
    "Accuracy = (TP + TN)/(TP + TN + FP + FN)\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy\n",
    "accuracy_score(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparemos la performance que obtuvimos con la performance del modelo nulo.\n",
    "\n",
    "El modelo nulo es el que predice todas las instancias con la etiqueta de la clase mayoritaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# null accuracy\n",
    "\n",
    "# comparamos la performance del modelo con lo que obtenemos si siempre elegimos la clase mayoritaria como predicción\n",
    "\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La clase mayoritaria es <=50K.\n",
    "\n",
    "Calculemos null_acuracy como si en test hubieramos predicho <=50K para todos los registros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "tn = 6829\n",
    "fp = 0\n",
    "fn = 2220\n",
    "null_accuracy = (tp + tn)/(tp + tn + fp + fn)\n",
    "null_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que null accuracy coincide con la proporción de clase mayoritaria, debido a que el modelo nulo de clasificación es predecir la moda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test.value_counts(normalize=True).max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculemos la matriz de confusión sobre los datos de test y grafiquemos el heatmap de esta matriz.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "\n",
    "conf_mat = confusion_matrix(Y_test, Y_pred)\n",
    "\n",
    "print('Confusion matrix\\n\\n', conf_mat)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', conf_mat[1,1])\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', conf_mat[0,0])\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', conf_mat[0,1])\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', conf_mat[1,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_mat_df = pd.DataFrame(data=conf_mat, \n",
    "                           index=['Actual Negative: 0', 'Actual Positive: 1'], \n",
    "                           columns=['Predict Negative: 0', 'Predict Positive: 1'])\n",
    "\n",
    "sns.heatmap(conf_mat_df, annot=True, fmt='d', cmap='YlGnBu');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
