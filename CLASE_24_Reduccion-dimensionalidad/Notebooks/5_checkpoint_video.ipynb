{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Reducción de la dimensionalidad\n",
    "\n",
    "Manifold learning es usado habitualmente para entender la relación entre datos de alta dimensionalidad. \n",
    "\n",
    "Un caso muy común es el análisis de imágenes.\n",
    "\n",
    "Por ejemplo: un set de imágenes con 1000 pixels cada una puede ser pensado como una colección de puntos en 1000 dimensiones, donde cada valor representa el brillo de cada pixel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "En esta práctica trabajaremos con un [dataset de imágenes de caras](http://vis-www.cs.umass.edu/lfw/). \n",
    "\n",
    "El dataset se llama \"Labeled Faces in the Wild\" y es una base de datos para trabajar con reconcimiento de rostros. \n",
    "\n",
    "Contiene alrededor de 13000 imágenes recolectadas de la web (nuestro dataset reducido tiene aprox. 2300). \n",
    "\n",
    "Cada cara fue taggeada con el nombre de la persona. \n",
    "\n",
    "Utilizaremos técnicas para reducir la dimensionalidad de las imágenes y poder visualizarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import offsetbox\n",
    "import joblib\n",
    "#from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import Isomap\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 - Carga de datos\n",
    "\n",
    "**Nota Importante:** el dataset está en almacenado en un objeto Bunch, que es un objeto tipo diccionario al que se accede a sus claves como si fueran atributos. \n",
    "\n",
    "Podemos acceder a las imagenes de dos formas, con *faces.data* y con *faces.images*. \n",
    "\n",
    "En *face.images*, se mantiene el formato de la imagen, es decir que vamos a tener un array de 2D para cada imagen más una dimensión para almacenar cada foto. En *faces.data* los datos están vectorizados para poder usarlos como input de un modelo. Se rompe la estructura 2D de la foto y tenemos solamente una dimensión para cada imagen.\n",
    "\n",
    "Usemos `shape` para ver las dimensiones de `faces.data` y de `faces.images`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos el dataset \n",
    "faces = joblib.load(\"../Data/faces_p2.dump\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "62*47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tenemos 2.370 imágenes cada una con 2.914 pixels. \n",
    "\n",
    "Podemos pensar estas imágenes como puntos en un espacio de 2.914 dimensiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Visualización\n",
    "\n",
    "Usando `matplotlib` hagamos una visualización rápida de 32 imágenesen una grilla de 4 filas y 8 columna para ver con qué estamos trabajando.\n",
    "\n",
    "Ayuda: \n",
    "\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.ndarray.flat.html\n",
    "\n",
    "https://www.w3schools.com/python/ref_func_enumerate.asp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# este argumento elimina los ticks de la grilla subplot_kw=dict(xticks=[], yticks=[])\n",
    "fig, ax = plt.subplots(4, 8, subplot_kw=dict(xticks=[], yticks=[]))\n",
    "#fig, ax = plt.subplots(4, 8)\n",
    "for i, axi in enumerate(ax.flat):\n",
    "    axi.imshow(faces.images[i], cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faces.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - PCA\n",
    "\n",
    "Nos gustaría poder representar estas imágenes (que están en un espacio 2.914-dimensional) en menor dimensionalidad para poder aprender las relaciones fundamentales entre las imágenes. Una primera forma simple de comenzar es computar sus componentes principales y examinar la razón de varianza explicada, que nos da una idea de cuántos componentes principales se requieren para poder describir estos datos.\n",
    "\n",
    "**3.1** Usando `StandardScaler` transformar `faces.data`\n",
    "\n",
    "**3.2** Sobre esos datos transformados calcular las primeras 100 componentes principales\n",
    "\n",
    "**3.3** Graficar el porcentaje de varianza explicada en función de la cantidad de componenetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_sclr = StandardScaler()\n",
    "X = std_sclr.fit_transform(faces.data)\n",
    "\n",
    "model_pca = PCA(100).fit(X)\n",
    "\n",
    "explained_variance = model_pca.explained_variance_ratio_\n",
    "\n",
    "#print(explained_variance)\n",
    "\n",
    "cumulative_explained_variance = np.cumsum(explained_variance)\n",
    "\n",
    "#print(cumulative_explained_variance)\n",
    "\n",
    "plt.plot(cumulative_explained_variance)\n",
    "plt.xlabel('número de componentes')\n",
    "plt.ylabel('% de varianza explicada');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que para este dataset alrededor de 100 componentes principales son necesarios para preservar el 90% de la varianza. \n",
    "\n",
    "Esto nos dice que, en principio, este dataset que es altamente multidimensional no puede ser descripto con pocos componentes lineales.\n",
    "\n",
    "Cuando este es el caso, métodos de manifold learning como T-SNE o IsoMap pueden ser de mucha ayuda. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Imágenes ubicadas según las primeras dos componentes de PCA\n",
    "\n",
    "Comencemos ploteando los datos usando las primeras dos componentes de PCA para ver los resultados que obtenemos usando la función `plot_components`\n",
    "\n",
    "`plot_components` va a graficar thumbnails de las imágenes en las coordenadas de la proyección, que es el output de una proyección bidimensional de todas las imágenes de input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_components(proj, images=None, ax=None, thumb_frac=0.05, cmap='gray'):\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "    # get axis from plot -  https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.gca.html\n",
    "    ax = ax or plt.gca()\n",
    "    \n",
    "    coord_x = proj[:, 0]\n",
    "    coord_y = proj[:, 1]\n",
    "    ax.plot(coord_x, coord_y, '.k')    \n",
    "    # símbolo . color k (black)\n",
    "    \n",
    "    if images is not None:\n",
    "                \n",
    "        min_dist_2 = (thumb_frac * max(proj.max(0) - proj.min(0))) ** 2\n",
    "        shown_images = np.array([2 * proj.max(0)])\n",
    "        \n",
    "        for i in range(proj.shape[0]):\n",
    "            \n",
    "            dist = np.sum((proj[i] - shown_images) ** 2, 1)\n",
    "            \n",
    "            # don't show points that are too close\n",
    "            if np.min(dist) >= min_dist_2:                        \n",
    "                \n",
    "                #https://numpy.org/doc/stable/reference/generated/numpy.vstack.html\n",
    "                shown_images = np.vstack([shown_images, proj[i]])\n",
    "            \n",
    "                # grafica las thumbnails:\n",
    "                imagebox = offsetbox.AnnotationBbox(offsetbox.OffsetImage(images[i], cmap=cmap), proj[i])\n",
    "                ax.add_artist(imagebox)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_2cp = PCA(n_components=2)\n",
    "proj_pca = pca_2cp.fit_transform(X)\n",
    "\n",
    "# list[<start>:<stop>:<step>]\n",
    "plot_components(proj_pca, images = faces.images[:, ::2, ::2])\n",
    "#plot_components(proj_iso, images=faces.images[:, :, :])\n",
    "#plot_components(proj_iso, images=faces.images[:, ::3, ::3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Isomap\n",
    "\n",
    "Proyectemos ahora los datos en 2 dimensiones usando Isomap y usemos `plot_components` para visualizar los resultados\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.Isomap.html#sklearn.manifold.Isomap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isomap_2cp = Isomap(n_components=2)\n",
    "proj_iso = isomap_2cp.fit_transform(faces.data)\n",
    "\n",
    "plot_components(proj_iso, images=faces.images[:, ::2, ::2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 - TSNE\n",
    "\n",
    "Proyectemos ahora los datos en 2 dimensiones usando T-SNE y usemos `plot_components` para visualizar los resultados\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html#sklearn.manifold.TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "proj_tsne = tsne.fit_transform(faces.data)\n",
    "\n",
    "plot_components(proj_tsne, images=faces.images[:, ::2, ::2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es interesante: las primeras dos dimensiones del T-SNE parecen describir dos características globales de las imágenes.\n",
    "    \n",
    "  * el brillo parece decrecer de abajo hacia arriba\n",
    "  * la orientación de la cara parece variar de derecha a izquierda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
