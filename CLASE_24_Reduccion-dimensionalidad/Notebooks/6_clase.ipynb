{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "El dataset tiene información sobre propiedades en Boston. El objetivo es predecir el precio de estas propiedades.\n",
    "\n",
    "https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data\n",
    "\n",
    "http://jse.amstat.org/v19n3/decock.pdf\n",
    "\n",
    "Para ver la descripción de los campos que componen este dataset:\n",
    "<a href=\"../Data/data_description.txt\">data_description</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema\n",
    "\n",
    "Transformando las variables del dataset de propiedades en Boston usando StandardScaler y OneHotEncoding, vamos a estimar los valores del campo `SalePrice` usando modelos de regresión lineal.\n",
    "\n",
    "Después, vamos a comparar los resultados de las predicciones de estos modelos con los que obtenemos usando como variables explicativas la proyección en las componentes principales del dataset transformado.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 1 - Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/ames_housing.csv')\n",
    "target = data[\"SalePrice\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 2 - Categorical y Non-categorical \n",
    "\n",
    "**2.1** Determinemos qué variables que forman el dataset son categóricas. Consideremos categóricas variables numéricas que tienen como máximo cinco valores distintos.\n",
    "\n",
    "**2.2** Usemos `pandas.Series.astype` para convertir esas nuevas columnas categóricas en `numpy.object`\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Categorical.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los valores que tienen las variables numéricas que consideramos categóricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las nuevas columnas categóricas están en la variable `new_categorical_columns`, convirtamos esas columnas en tipo np.object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 3 - Valores nulos\n",
    "\n",
    "Calculemos el porcentaje de nulos en cada columna.\n",
    "\n",
    "Eliminemos aquellas columnas que tengan al menos el 40% de los registros con valores nulos.\n",
    "\n",
    "Eliminemos aquellos registros que tengan al menos un valor nulo en las columnas que no fueron eliminadas en el paso anterior.\n",
    "\n",
    "Eliminemos la columna `Id` del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 4 - Train test sets\n",
    "\n",
    "Dividamos el dataset de registros completos en 70-30 train test, definiendo como X_train, X_test las matrices de features e Y_train, Y_test los vectores target.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 5 - Feature engineering\n",
    "\n",
    "**5.1** Usemos one hot encoding para transformar las variables categóricas de los dataset de train y test\n",
    "\n",
    "**5.2** Usemos StandardScaler para transformar las variables numéricas de los dataset de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 6 - Regresión lineal\n",
    "\n",
    "**6.1** Constuyamos un modelo de regresión lineal múltiple sobre los datasets de train y test transformados.\n",
    "\n",
    "**6.2** Construyamos otro modelo usando regularización Lasso\n",
    "\n",
    "**6.2** Construyamos un terecer modelo usando regularización Ridge\n",
    "\n",
    "Para los tres modelos calculemos:\n",
    "* mean_absolute_error\n",
    "* mean_squared_error\n",
    "* raiz cuadrada de mean_squared_error\n",
    "* r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularización Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regularización Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 7 - PCA\n",
    "\n",
    "Grafiquemos la varianza explicada por 100, 50 y 30 componentes principales del dataset de train transformado con one hot encoding y StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 8 - Proyección sobre las componentes principales del conjunto de entrenamiento\n",
    "\n",
    "Construyamos un conjunto de entrenamiento y uno de test para una regresión lineal usando las primeras 30 componentes principales del conjunto de entrenamiento usado en la regresión lineal del ejercicio anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio 9 - Regresión lineal sobre componentes principales\n",
    "\n",
    "**6.1** Constuyamos un modelo de regresión lineal múltiple sobre los datasets de train y test usando como features la proyección sobre las componentes principales calculadas en el ejercicio anterior. ¿Qué supuesto podemos asegurar que se cumple usando las componentes principales como variables explicativas?\n",
    "\n",
    "**6.2** Construyamos otro modelo usando regularización Lasso sobre los mismos features que en 6.1\n",
    "\n",
    "**6.2** Construyamos un terecer modelo usando regularización Ridge sobre los mismos features que en 6.1\n",
    "\n",
    "Para los tres modelos calculemos:\n",
    "* mean_absolute_error\n",
    "* mean_squared_error\n",
    "* raiz cuadrada de mean_squared_error\n",
    "* r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cada una de las \"nuevas\" variables después de PCA son independientes entre sí. \n",
    "# los supuestos de un modelo lineal requieren que nuestras variables independientes sean independientes entre sí. \n",
    "# Si ajustamos un modelo de regresión lineal con estas \"nuevas\" variables, este supuesto necesariamente se cumplirá.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que, para la regresión lineal múltiple, todas las métricas que obtenemos con el modelo entrenado con las componentes principales son mejores que las del modelo sin esta transformación.\n",
    "\n",
    "Con regularización de Lasso o Ridge no son tan evidentes las diferencias entre usar o no la proyección sobre las componenetes principales.\n",
    "\n",
    "Una ventaja de este segundo modelo es que usa 30 features mientras que el primero usa 280.\n",
    "\n",
    "Como ejercicio adicional, repitan los tres modelos usando en el ejercicio 5 \n",
    "`encoder = OneHotEncoder(categories = encoder_categories, sparse=False, drop=\"first\")`\n",
    "\n",
    "Y comparen estos nuevos resultados.\n",
    "\n",
    "**¿Qué significa que R2 sea negativo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "https://www.kaggle.com/miguelangelnieto/pca-and-regression"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
