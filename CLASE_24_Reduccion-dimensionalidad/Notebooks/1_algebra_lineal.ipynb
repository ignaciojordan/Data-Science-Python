{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algebra lineal - **Opcional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro\n",
    "\n",
    "Esta notebook es un repaso de álgebra lineal. Este contenido no es indispensable para resolver las notebooks que siguen en esta clase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectores\n",
    "\n",
    "Se llama vector de dimensión $n$, a una tupla de números reales (que se llaman componentes del vector). \n",
    "\n",
    "El conjunto de todos los vectores de dimensión $n$ se representa como $R ^n$.\n",
    "\n",
    "Así, un vector $v$ perteneciente a un espacio $R^n$ se representa como:\n",
    "\n",
    "$v=(a_1,a_2,a_3,\\dots ,a_n)$, donde $v \\in R^n$\n",
    "\n",
    "### Producto interno o escalar\n",
    "\n",
    "En el espacio vectorial $R^n$ se suele definir el producto interno (producto punto) por:\n",
    "$a \\cdot b =(a_1,a_2,a_3,...,a_n) \\cdot (b_1,b_2,b_3,...,b_n) = a_1b_1 + a_2b_2 + ... + a_nb_n = \\sum_{i=1}^n a_i \\cdot b_i$\n",
    "\n",
    "#### Ortogonalidad\n",
    "\n",
    "En un espacio vectorial con producto interior V, dos vectores $x\\in V$ e $y\\in V$ son ortogonales si el producto escalar de $\\langle x,y\\rangle$ es cero. \n",
    "\n",
    "O sea, \n",
    "\n",
    "$\\langle x , y\\rangle = x \\cdot y =(x_1,x_2,x_3,...,x_n) \\cdot (y_1,y_2,y_3,...,y_n) = x_1y_1 + x_2y_2 + ... + x_ny_n = \\sum_{i=1}^n x_i \\cdot y_i = 0$\n",
    "\n",
    "#### Módulo\n",
    "\n",
    "Dado un vector del espacio euclídeo $(a_1, a_2, .... a_n)$. Su norma se define como $\\sqrt{a_1^2 + a_2^2 + ... + a_n^2}$\n",
    "\n",
    "Observemos que $\\langle a , a\\rangle = \\|a\\|^2$ (el producto interno de $a$ consigo mismo es igual a la norma de $a$ al cuadrado)\n",
    "\n",
    "#### Ortonormalidad\n",
    "\n",
    "Los n vectores $v_1, v_2, ...,v_n$ en V se llaman ortogonales y normales, denominados ortonormales, cuando satisfacen las dos condiciones siguientes.\n",
    "\n",
    " 1. $\\|v_{i}\\|=1,\\ \\forall i\\in \\{1,2,\\dots ,n\\}$\n",
    " \n",
    " 2. $\\langle v_i,v_j\\rangle = 0, \\textrm {cuando} \\ i\\neq j$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrices\n",
    "\n",
    "Una matriz es un arreglo bidimensional de números\n",
    "\n",
    "<img src='./img/matriz.png' align='center' width=30%/>\n",
    "\n",
    "Una matriz en general se representa por medio de una letra mayúscula (A,B, …) y sus elementos con la misma letra en minúscula (a,b, …), con un doble subíndice donde el primero indica la fila y el segundo la columna a la que pertenece.\n",
    "\n",
    "Las matrices se utilizan para múltiples aplicaciones y sirven, en particular, para representar los coeficientes de los sistemas de ecuaciones lineales o para representar transformaciones lineales dada una base.\n",
    "\n",
    "### Operaciones básicas entre matrices\n",
    "\n",
    "#### Suma\n",
    "\n",
    "Sean $A,B \\in M_{{n\\times m}}$\n",
    "\n",
    "\n",
    "$\\begin{bmatrix}2 & 2 & 1\\\\3 & 2 & 1\\\\2 & 3 & 2\\\\2 & 0 & 4\\end{bmatrix} \\quad + \\quad \\begin{bmatrix}0 & 1 & 4\\\\1 & 4 & 0\\\\2 & 1 & 1\\\\0 & 2 & 2\\end{bmatrix}\\quad = \\quad \\begin{bmatrix}2&3&5\\\\4&6&1\\\\4&4&3\\\\2&2&6\\end{bmatrix}$\n",
    "\n",
    "Se define la operación de suma o adición de matrices como una operación binaria \n",
    "\n",
    "$+:M_{m\\times n} \\times M_{m\\times n} \\longrightarrow M_{m\\times n}$ tal que \n",
    "\n",
    "$(A,B)\\mapsto C=A+B$ donde $c_{ij}=a_{ij}+b_{ij}$\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Sea $A,B\\in M_{3 \\times 3}$\n",
    "\n",
    "$\\begin{bmatrix} 1 & 3 & 2\\\\ 1 & 0 & 0\\\\ 1 & 2 & 2 \\end{bmatrix} + \\begin{bmatrix} 1 & 0 & 5\\\\7 & 5 & 0\\\\ 2 & 1 & 1\\end{bmatrix}= \\begin{bmatrix} 1+1 & 3+0 & 2+5 \\\\ 1+7 & 0+5 & 0+0 \\\\ 1+2 & 2+1 & 2+1\\end{bmatrix} = \\begin{bmatrix} 2 & 3 & 7\\\\ 8 & 5 & 0 \\\\ 3 & 3 & 3 \\end{bmatrix}$\n",
    "\n",
    "No es necesario que las matrices sean cuadradas.\n",
    "\n",
    "A la luz de estos ejemplos es inmediato ver que dos matrices se pueden sumar solamente si ambas tienen el mismo tamaño. \n",
    "\n",
    "\n",
    "#### Producto por un escalar\n",
    "\n",
    "Sean $A\\in M_{n\\times m}$ y $\\lambda$ un escalar (un número)\n",
    "\n",
    "Se define la operación de producto por un escalar como una función \n",
    "\n",
    "$(\\lambda ,A)\\mapsto B=\\lambda A$ y donde $b_{ij}=\\lambda a_{ij}$\n",
    "\n",
    "\n",
    "Ejemplo: \n",
    "\n",
    "Sea  $A \\in M_{2\\times 3}$ y $2\\in R$\n",
    "\n",
    "$2 \\begin{bmatrix}1&\\,\\,\\ \\,8&-3\\\\4&-2&\\,\\,\\,6\\end{bmatrix} = \\begin{bmatrix}2(1)&\\,\\,\\,\\,2(8)&2(-3)\\\\2(4)&2(-2)&\\,\\,\\,\\,2(6)\\end{bmatrix} = \\begin{bmatrix}2&\\,16&-6\\\\8&-4&\\,12\\end{bmatrix}$\n",
    "\n",
    "Es inmediato observar que el producto por un escalar da como resultado una matriz del mismo tamaño que la original. \n",
    "\n",
    "#### Producto de matrices\n",
    "\n",
    "Sea $f:V\\longrightarrow W$  $f(x)=Ax$ donde $x$ es la representación de un vector columna en el espacio $V$\n",
    "\n",
    "Si tenemos dos aplicaciones lineales $f:V\\longrightarrow W$ y $g:W\\longrightarrow U$ entonces $f(x)=Bx$ y $g(x)=Ax$, luego la aplicación (la composición de funciones $f$ y $g$) $ g\\circ f:V\\longrightarrow U$ se representará como $g\\circ f(x)=g(f(x))=g(Bx)=ABx$ donde $AB$ es el producto de las representaciones matriciales de $f,g$. Notemos que la composición no se puede dar entre cualquier aplicación sino entre aplicaciones que vayan de $V\\rightarrow W \\rightarrow U$, en particular debe de haber una relación entre las dimensiones de los espacios vectoriales. Una vez dicho esto podemos definir el producto de la siguiente manera.\n",
    "\n",
    "Sean $A\\in M_{n\\times m}$ y $B\\in M_{m\\times p}$. Se define el producto de matrices como una función $M_{n\\times m} \\times M_{m\\times p}\\longrightarrow M_{n\\times p}$ tal que $(A, B)\\mapsto C=AB$ y donde $c_{ij}=\\sum_{k=1}^{m}a_{ik}b_{kj}$ para todo $i,j$\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "Sean $A \\in M_{2 \\times 3}$ y $B \\in M_{3 \\times 2}$\n",
    "\n",
    "$\\begin{bmatrix}1 & 0 & 2\\\\-1& 3& 1\\end{bmatrix}\\begin{bmatrix}3 & 1\\\\2 & 1\\\\1 & 0\\end{bmatrix} = \\begin{bmatrix}1(3) + 0(2) + 2(1) & 1(1) + 0(1) + 2(0) \\\\ -1(3) + 3(2) + 1(1) & -1(1) + 3(1) + 1(0) \\end{bmatrix} = \\begin{bmatrix}5 & 1 \\\\ 4 & 2 \\end{bmatrix}$\n",
    "\n",
    "dónde la matriz resultado es una matriz $C\\in M_{2\\times 2}$\n",
    "\n",
    "#### Matriz identidad\n",
    "\n",
    "La matriz identidad $I_n$ de orden n es la matriz n por n en la cual todos los elementos de la diagonal principal son iguales a 1 y todos los demás elementos son iguales a 0. \n",
    "\n",
    "Por ejemplo, si n = 3:\n",
    "\n",
    "${I} _{3} = \\begin{bmatrix}1&0&0\\\\0&1&0\\\\0&0&1\\end{bmatrix}$\n",
    "\n",
    "#### Traspuesta\n",
    "\n",
    "Sea $A$ una matriz con $m$ filas y $n$ columnas. La matriz traspuesta, denotada con $A^t$\n",
    "\n",
    "Está dada por:\n",
    "\n",
    "$A^t_{ij}=A_{ji},\\ 1\\leq i\\leq m,\\ 1\\leq j\\leq n$\n",
    "\n",
    "En donde el elemento $a_{ji}$ de la matriz original A se convertirá en el elemento $a_{ij}$ de la matriz traspuesta $A^t$\n",
    "\n",
    "Ejemplo:\n",
    "\n",
    "$\\begin{bmatrix}a & b \\\\ c & d \\\\ e & f\\end{bmatrix}^t = \\begin{bmatrix}a & c & e \\\\ b & d & f\\end{bmatrix}$\n",
    "\n",
    "\n",
    "#### Determinante\n",
    "\n",
    "1. Si la dimensión de la matriz es 1, sólo tiene un elemento y su determinante es dicho elemento:\n",
    "\n",
    "$A = (a)$\n",
    "$|A| = a$\n",
    "\n",
    "2. La matriz cuadrada de dimensión 2 tiene la forma\n",
    "\n",
    "$A = \\begin{bmatrix} a_{11} & a_{12}\\\\a_{21} & a_{22} \\end{bmatrix}$\n",
    "\n",
    "Calculamos el determinante restando el producto de los elementos de las diagonales:\n",
    "\n",
    "$|A| =  a_{11} .  a_{22} -  a_{12} .  a_{21}$\n",
    "\n",
    "3. Regla de Laplace\n",
    "\n",
    "La regla de Laplace para calcular determinantes se puede aplicar para **matrices cuadradas de cualquier dimensión**, pero normalmente se hace para dimensión mayor que 3.\n",
    "\n",
    "Hay dos versiones de la regla: desarrollo por una fila y desarrollo por una columna.\n",
    " \n",
    "Consejo: desarrollar por la fila o la columna que tenga más ceros\n",
    "\n",
    "Desarrollo por la fila $i$ de la matriz cuadrada $A$ de dimensión $n$: \n",
    "\n",
    "$| A | = \\sum_{j=1}^n{a_{ij}. (-1)^{i+j} |A_{ij}|}$ \n",
    "\n",
    "donde $|A_{ij}|$ es la matriz de dimensión $n-1$ resultado de eliminar la fila $i$ y la columna $j$ de $A$\n",
    "\n",
    "Por lo tanto, si la matriz es de dimensión $n$ tendremos que calcular $n$ determinantes de matrices de dimensión $n-1$\n",
    "\n",
    "Desarrollo por la columna $j$ de la matriz cuadrada $A$ de dimensión $n$: \n",
    "\n",
    "$| A | = \\sum_{i=1}^n{a_{ij}. (-1)^{i+j} |A_{ij}|}$ \n",
    "\n",
    "Ejemplo\n",
    "\n",
    "Calcularemos el determinante de la siguiente matriz de dimensión 3:\n",
    "\n",
    "<img src='./img/determinante_1.png' align='center' width=15%/> \n",
    "\n",
    "Como tenemos un 0 en la segunda fila, desarrollamos por la fila 2:\n",
    "\n",
    "<img src='./img/determinante_2.png' align='center' width=25%/> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autovalores y autovectores\n",
    "\n",
    "Sea $A \\in R^{n \\times n}, \\lambda \\in R$ es autovalor de $A$ si y sólo si existe un vector $v \\in R^{n \\times 1}$ no nulo tal que\n",
    "\n",
    "$A . v = \\lambda . v,v \\neq 0$\n",
    "\n",
    "$v$ se llama autovector asociado a $\\lambda$\n",
    "\n",
    "Esta ecuación puede rescribirse como\n",
    "\n",
    "$(A - \\lambda. I). v = 0, v \\neq 0$\n",
    "\n",
    "Para que esto se cumpla para cualquier valor de $v$:\n",
    "\n",
    "$det(A - \\lambda. I) = 0$ \n",
    "\n",
    "Esta es la ecuación característica de la matriz $A$.\n",
    "\n",
    "Y $p(\\lambda) = det(A - \\lambda. I)$ es n polinomio de grado $n$ dependiente de $\\lambda$ que se llama polinomio característico de la matriz $A$\n",
    "\n",
    "Las raíces del polinomio característico son los autovalores de $A$\n",
    "\n",
    "Una vez hallados los autovalores volvemos a la expresión original y para cada $\\lambda$ resolvemos el sistema\n",
    "\n",
    "$(A - \\lambda. I). v = 0$ \n",
    "\n",
    "y hallamos los $v$ que son los autovectores correspondientes a cada $\\lambda$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "1. Tenemos un dataset con D features (D = 3)\n",
    "\n",
    "<img src='./img/pca_1.png' align='center' width=20%/> \n",
    "\n",
    "2. Calculamos la media de cada feature del dataset\n",
    "\n",
    "<img src='./img/pca_2.png' align='center' width=20%/> \n",
    "\n",
    "<img src='./img/pca_3.png' align='center' width=20%/> \n",
    "\n",
    "3. Calculamos la matriz de covarianzas del dataset\n",
    "\n",
    "<img src='./img/pca_4.png' align='center' width=50%/> \n",
    "\n",
    "<img src='./img/pca_5.png' align='center' width=30%/> \n",
    "\n",
    "<img src='./img/pca_6.png' align='center' width=40%/> \n",
    "\n",
    "Algunos puntos para remarcar:\n",
    "\n",
    "* En la diagonal en azul vemos los valores de las varianzas de las calificaciones en los exámenes. El examen de arte tiene la varianza máxima (720), y el examen de inglés tiene la varianza mínima (360). Por lo tanto podemos decir que la variabilidad en las calificaciones de arte es mayor que en las calificaciones de inglés.\n",
    "\n",
    "* Fuera de la diagonal y en negro vemos los valores de las covarianzas.\n",
    "\n",
    "a. La covarianza entre matemática e inglés es positiva (360) y la covarianza entre matemática y arte es positiva (180). Esto significa que cuando el valor de las calificaciones en matemática aumenta las calificaciones en arte y en inglés también aumentan, y vice versa.\n",
    "\n",
    "b. La covarianza entre inglés y arte es cero. Esto implica que no es predecible una relación entre los valores de las calificaciones de ambos.\n",
    "\n",
    "\n",
    "4. Calculamos los autovectores y autovalores de la matriz de covarianzas\n",
    "\n",
    "Los autovalores son los $\\lambda$ que resuelven la ecuación\n",
    "\n",
    "<img src='./img/pca_7.png' align='center' width=15%/> \n",
    "\n",
    "<img src='./img/pca_8.png' align='center' width=30%/> \n",
    "\n",
    "<!--<img src='./img/pca_9.png' align='center' width=30%/> -->\n",
    "\n",
    "<!--<img src='./img/pca_10.png' align='center' width=30%/> -->\n",
    "\n",
    "<img src='./img/pca_11.png' align='center' width=30%/> \n",
    "\n",
    "<!--<img src='./img/pca_12.png' align='center' width=30%/> -->\n",
    "\n",
    "<img src='./img/pca_13.png' align='center' width=30%/> \n",
    "\n",
    "<img src='./img/pca_14.png' align='center' width=35%/> \n",
    "\n",
    "Los tres valores de $\\lambda$ obtenidos son los autovalores que resuelven la ecuación característica.\n",
    "\n",
    "Los autovectores asociados a esos autovalores son:\n",
    "\n",
    "<img src='./img/pca_15.png' align='center' width=35%/> \n",
    "\n",
    "5. Ordenamos los autovectores en orden decreciente de los autovalores asociados, y elegimos los k autovectores con máximos autovalores para construir una matriz W de dimensión D x k (los autovectores seleccionados son las columnas de esta matriz)\n",
    "\n",
    "<img src='./img/pca_16.png' align='center' width=14%/> \n",
    "\n",
    "El k que elegimos es 2 (queremos representar nuestro dataset con sólo dos features). Entonces la matriz W es:\n",
    "\n",
    "<img src='./img/pca_17.png' align='center' width=25%/> \n",
    "\n",
    "donde la primera columna es el autovector asociado al máximo autovalor (910), y la segunda columna es el autovector asociado al segundo máximo autovalor (629)\n",
    "\n",
    "6. Usamos la matriz de autovectores de dimensión d x k para transformar nuestro dataset\n",
    "\n",
    "Usamos la matriz W resultado del paso anterior para transformar nuestro dataset inicial como:\n",
    "\n",
    "$U = t(W) X$ donde $t(W)$ es la transpuesta de W\n",
    "\n",
    "Así, calculamos dos componentes principales y proyectamos los datos del dataset original en un nuevo subespacio, $U$ es una matriz que tiene los datos originales representados en el sistema de coordenadas definido por las k componentes principales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Referencias\n",
    "\n",
    "Essence of linear algebra - (muy bueno!)\n",
    "https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab\n",
    "\n",
    "Basics and Examples of Principal Component Analysis (PCA) - \n",
    "https://www.projectrhea.org/rhea/index.php/PCA_Theory_Examples\n",
    "\n",
    "The mathematics behind principal component analysis - \n",
    "https://towardsdatascience.com/the-mathematics-behind-principal-component-analysis-fff2d7f4b643\n",
    "\n",
    "Variance-Covariance Matrix - \n",
    "https://stattrek.com/matrix-algebra/covariance-matrix.aspx\n",
    "\n",
    "Análisis de Componentes Principales - \n",
    "https://www.cienciadedatos.net/documentos/35_principal_component_analysis\n",
    "\n",
    "Principal component analysis with linear algebra - \n",
    "https://www.math.upenn.edu/~kazdan/312S13/JJ/PCA-JJ.pdf\n",
    "\n",
    "Autovalores y autovectores - \n",
    "https://aga.frba.utn.edu.ar/autovalores-autovectores-definiciones-propiedades/\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
