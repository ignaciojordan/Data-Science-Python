{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../../common/logo_DH.svg\" align='left' width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "84PdwHJxMxmA"
   },
   "source": [
    "# LAB: KNN\n",
    "\n",
    "## 1. Introducción\n",
    "\n",
    "El objetivo de este ejercicio es clasificar si un determinado tipo de vino es de alta o baja calidad. Para eso usaremos un dataset que contiene un set amplio de _features_ vinculados a diversas características del vino, tales como acidez, azúclar, densidad, ph, si es tinto, etc.\n",
    "\n",
    "Usaremos como target high_quality, una discretización de la variable quality.\n",
    "\n",
    "Comencemos leyendo los datos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSVfuqizMxmD",
    "outputId": "cc8f0310-896c-4680-e115-16094f2e97bc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eSVfuqizMxmD",
    "outputId": "cc8f0310-896c-4680-e115-16094f2e97bc"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/wine.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Análisis exploratorio\n",
    "\n",
    "- ¿Cuántas observaciones hay en la tabla? ¿Tenemos datos faltantes?\n",
    "- ¿Cómo se distribuye la variable target?\n",
    "- ¿Existen variables redundantes?\n",
    "- ¿Qué variables están más correlacionadas con el _target_?\n",
    "- ¿Cómo podemos visualizar las relaciones entre cada par de variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuántas observaciones hay en la tabla? ¿Tenemos datos faltantes?\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cómo se distribuye la variable target?\n",
    "df['high_quality'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Existen variables redundantes?\n",
    "# high_quality es una binarización de la variable quality\n",
    "df.groupby('quality')['high_quality'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_red es una binarización de la variable color\n",
    "df.groupby('color')['is_red'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Qué variables están más correlacionadas con el target?\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure(figsize=(20,10))\n",
    "sns.heatmap(df.corr(), annot=True, vmin=-1, cmap='Blues');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cómo podemos visualizar las relaciones entre cada par de variables?\n",
    "sns.pairplot(df);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da8yHLByMxmh"
   },
   "source": [
    "## 3. Preprocesamiento y limpieza del dataset\n",
    "\n",
    "- Construir la matriz de _features_, prestando especial atención a no incluir las variables redundantes ni replicar información del _target_ en ninguna _feature_ (¡siempre hay que evitar el filtrado de información!)\n",
    "- Construir la variable _target_: high_quality\n",
    "- Separar los conjuntos de entrenamiento y testeo, estratificando por clase\n",
    "- ¿Necesitamos estandarizar las variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la matriz de features\n",
    "X = df.drop(['color', 'quality', 'high_quality'], axis=1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construir la variable target: high_quality\n",
    "y = df['high_quality']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar los conjuntos de entrenamiento y testeo, estratificando por clase\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Necesitamos estandarizar las variables?\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da8yHLByMxmh"
   },
   "source": [
    "## 4. Entrenando KNN\n",
    "\n",
    "- Experimentar con diferentes valores para el hiperparámetro _k_ y evaluar el accuracy promedio del modelo y su dispersión en validación cruzada sobre el _traininig set_\n",
    "- Visualizar los resultados\n",
    "\n",
    "**Pista:** pueden tratar de generar una función que encapsule la generación de la tabla de resultados vimos en la notebook 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbUAd-nSMxmj"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XbUAd-nSMxmj"
   },
   "outputs": [],
   "source": [
    "def scores_knn(X, y, start,stop,step):\n",
    "    \n",
    "    # Vamos a querer graficar los distintos valores del score de cross validation en función del hiperparámetro n_neighbors\n",
    "    # Para esto vamos a generar una lista de diccionarios que después se puede convertir fácilmente en DataFrame\n",
    "    \n",
    "    # Lista de diccionarios - la inicializamos vacío y por fuera del for loop para ir alimentándola en cada iteración\n",
    "    scores_para_df = []\n",
    "    \n",
    "    \n",
    "    for i in range(start,stop,step):\n",
    "        \n",
    "        # En cada iteración, instanciamos el modelo con un hiperparámetro distinto\n",
    "        model = KNeighborsClassifier(n_neighbors=i)\n",
    "\n",
    "        # cross_val_scores nos devuelve un array de 5 resultados, uno por cada partición que hizo automáticamente CV\n",
    "        kf = KFold(n_splits=10, shuffle=True, random_state=10)\n",
    "        cv_scores = cross_val_score(model, X, y, cv=kf)\n",
    "\n",
    "        # Para cada valor de n_neighbours, creamos un diccionario con el valor de n_neighbours y la media y el desvío de los scores\n",
    "        dict_row_score = {'score_medio':np.mean(cv_scores),'score_std':np.std(cv_scores),'n_neighbours':i}\n",
    "\n",
    "        # Guardamos cada uno en la lista de diccionarios\n",
    "        scores_para_df.append(dict_row_score)\n",
    "    \n",
    "    # Creamos el DF a partir de la lista de resultados\n",
    "    df_scores = pd.DataFrame(scores_para_df)\n",
    "    \n",
    "    # Incorporamos los límites inferior y superior, restando y sumando el valor del desvío estándar, respectivamente\n",
    "    df_scores['limite_inferior'] = df_scores['score_medio'] - df_scores['score_std']\n",
    "    df_scores['limite_superior'] = df_scores['score_medio'] + df_scores['score_std']\n",
    "    \n",
    "    # Retornamos el DF\n",
    "    return df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KEQtM2HhMxmo"
   },
   "outputs": [],
   "source": [
    "# Probamos de 1 a 20 vecinos\n",
    "df_scores= scores_knn(X_train, y_train, 1, 21, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos los resultados\n",
    "\n",
    "plt.plot(df_scores['n_neighbours'], df_scores['limite_inferior'], color='r')\n",
    "plt.plot(df_scores['n_neighbours'], df_scores['score_medio'], color='b')\n",
    "plt.plot(df_scores['n_neighbours'], df_scores['limite_superior'], color='r')\n",
    "plt.ylim(0.7, 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Prediciendo sobre _test_\n",
    "\n",
    "- Habiendo identificado la mejor configuración del modelo en el paso anterior, reentrenar sobre todo el _training set_ y predecir sobre _test_\n",
    "- ¿Qué accuracy obtenemos sobre _test_? ¿Cómo podemos saber si estamos ante un caso de sub-ajuste o sobre-ajuste?\n",
    "- Graficar la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos el score máximo\n",
    "df_scores.loc[df_scores.score_medio == df_scores.score_medio.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos el valor del k óptimo a una variable\n",
    "best_k = df_scores.loc[df_scores.score_medio == df_scores.score_medio.max(),'n_neighbours'].values[0]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos el modelo óptimo que nos había indicado cross validation\n",
    "model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Lo ajustamos sobre datos de entrenamiento\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluamos qué accuracy obtenemos en train\n",
    "accuracy_score(y_train, model.predict(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo utilizamos para predecir en test\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computamos el accuracy score en test\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Graficamos la matriz de confusión\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='.0f')\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Starter_LAB_Intro_Clasificacion.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
