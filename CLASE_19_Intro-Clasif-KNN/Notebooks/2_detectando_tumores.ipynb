{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../../common/logo_DH.svg\" align='left' width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_clasificando\"></a>\n",
    "# Detectando tumores malignos usando KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de Contenidos\n",
    "1. <a href='#section_intro'>Introducción</a>\n",
    "2. <a href='#section_baseline'>Un modelo de base</a>\n",
    "3. <a href='#section_optimizando'>Optimizando el valor de _k_</a>\n",
    "4. <a href=\"#section_confusion\">Matriz de confusión</a>\n",
    "5. <a href=\"#section_conclusion\">Conclusión</a>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_intro\"></a>\n",
    "##  Introducción\n",
    "\n",
    "En la notebook anterior, mostramos cómo funciona KNN aplicándolo un conjunto de datos sintéticos, de tan solo dos dimensiones, para poder generar una intuición visual acerca de cómo se comporta el algoritmo al momento de generar predicciones. En lo cotidiano, típicamente trabajaremos con datasets de mayor dimensionalidad, con los cuales ya no podremos visualizar las fronteras de decisión que genera KNN. Sin embargo, esto no significa que no podamos aplicar la técnica, ya que las medidas de distancia que podemos utilizar aplican a cualquier cantidad de dimensiones.\n",
    "\n",
    "En esta notebook, vamos a trabajar con un dataset real de tumores mamarios con el objetivo de clasificar tumores benignos y malignos. Seguiremos los siguientes pasos:\n",
    "\n",
    "1. Cargar el dataset desde el módulo correspondiente de Scikit-Learn\n",
    "2. Preparar la matriz de _features_ y el vector *target*, separando los sets de _train_ y _test_\n",
    "3. Correr una primera prueba de KNN con la configuración de hiperparámetros por defecto, que será nuestro modelo de base\n",
    "4. Elegir el valor óptimo para el hiperparámetro `n_neighbors` utilizando validación cruzada\n",
    "5. Repetir el proceso pero estandarizando la matriz de _features_ para analizar qué efecto tiene sobre la _performance_ del algoritmo\n",
    "6. Graficar la matriz de confusión, una tabla que se utiliza comúnmente para inspeccionar visualmente los resultados de la clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Cargar el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset y visualizamos su descripción\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Preparar la matriz de _features_ y el vector _target_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos la matriz de features y visualizamos las primeras filas\n",
    "X = pd.DataFrame(cancer.data, columns = cancer.feature_names)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construimos el vector target y visualizamos las primeras filas\n",
    "y = pd.Series(cancer.target)\n",
    "y.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analizamos la proporción entre clases\n",
    "pd.Series(y).value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a la descripción del dataset, sabemos que la clase mayoritaria ($y=1$) corresponde a los tumores benignos, mientras que la minoritaria ($y = 0$) corresponde a los malignos. En este punto, es importante resaltar que **la etiqueta numérica asignada a cada clase es completamente arbitraria**. Si bien vamos a hablar comúnmente de **\"clase positiva\"** ($y=1$) y **\"clase negativa\"** ($y = 0$), esta nomenclatura es convencional y no guarda ningún tipo de valoración subjetiva al respecto de las cualidades de cada clase. Es decir, podríamos invertir las etiquetas y referirnos a los tumores malignos como clase positiva ($y=1$) y esto no traería aparejada ninguna complicación al momento de procesar los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hacemos el *train-test split*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El argumento stratify nos permite generar una división que respeta la misma proporción entre clases en ambos sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(y_train.value_counts(normalize=True).round(2))\n",
    "display(y_test.value_counts(normalize=True).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_baseline\"></a>\n",
    "## Un modelo de base\n",
    "\n",
    "Hecha la separación entre _train_ y *test*, ya podemos entrenar un KNN sobre este conjunto de datos. En esta primera prueba, trabajaremos con la configuración de los hiperparámetros del modelo que viene por defecto:\n",
    "\n",
    "#### 3. Correr una primera prueba de KNN con la configuración de hiperparámetros por defecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos la clase KNeighborsClassifier de módulo neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciamos el modelo con su configuración por defecto\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustamos a los datos de entrenamiento\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos etiquetas para los datos de test\n",
    "y_pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el accuracy del modelo\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nuestro modelo puede clasificar correctamente el 92% de los tumores del set de *test*. ¡Nada mal para una línea de base!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_optimizando\"></a>\n",
    "## Optimizando el valor de *k*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Elegir el valor óptimo para el hiperparámetro `n_neighbors`\n",
    "\n",
    "Ahora vamos a entrenar varios modelos de `KNeighborsClassifier` probando distintos valores posibles para el hiperparámetro `n_neighbors` dentro de un esquema de *cross-validation*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a querer graficar los distintos valores del score de cross validation\n",
    "# en función del hiperparámetro n_neighbors. Para esto generamos una lista de\n",
    "# diccionarios que después se puede convertir fácilmente en DataFrame.\n",
    "\n",
    "# Probamos todos los enteros desde el 1 hasta el 20\n",
    "# como posibles valores de n_neighbors a explorar.\n",
    "\n",
    "# Definimos la estrategia de validación cruzada\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=12)\n",
    "\n",
    "scores_para_df = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    \n",
    "    # En cada iteración, instanciamos el modelo con un hiperparámetro distinto\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    \n",
    "    # cross_val_scores nos devuelve un array de 5 resultados,\n",
    "    # uno por cada partición que hizo automáticamente CV\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    \n",
    "    # Para cada valor de n_neighbours, creamos un diccionario con el valor\n",
    "    # de n_neighbours y la media y el desvío de los scores\n",
    "    dict_row_score = {'score_medio':np.mean(cv_scores),\n",
    "                      'score_std':np.std(cv_scores), 'n_neighbors':i}\n",
    "    \n",
    "    # Guardamos cada uno en la lista de diccionarios\n",
    "    scores_para_df.append(dict_row_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el DataFrame a partir de la lista de diccionarios\n",
    "df_scores = pd.DataFrame(scores_para_df)\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Graficando la búsqueda del mejor hiperparámetro\n",
    "\n",
    "El valor de _scoring_ que utiliza por defecto `KNeighborsClassifier` es el accuracy, el porcentaje de casos bien clasificados. \n",
    "\n",
    "Una vez que tenemos la tabla con la _performance_ para cada valor del hiperparámetro, hacemos un gráfico con los valores obtenidos. Para darnos una idea de la dispersión, vamos a graficar también las líneas que indican un desvío estándar por encima y por debajo de la media. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos los límites inferior y superior\n",
    "df_scores['limite_inferior'] = df_scores['score_medio'] - df_scores['score_std']\n",
    "df_scores['limite_superior'] = df_scores['score_medio'] + df_scores['score_std']\n",
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados\n",
    "plt.plot(df_scores['n_neighbors'], df_scores['limite_inferior'], color='r')\n",
    "plt.plot(df_scores['n_neighbors'], df_scores['score_medio'], color='b')\n",
    "plt.plot(df_scores['n_neighbors'], df_scores['limite_superior'], color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos el score máximo\n",
    "df_scores.loc[df_scores.score_medio == df_scores.score_medio.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego de la validación cruzada, identificamos que el valor de `n_neighbors` que maximiza el *score* promedio es 8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Repetir el proceso pero estandarizando la matriz de *features*\n",
    "\n",
    "Dijimos que KNN es un método de _machine learning_ que se basa en calcular distancia. Entonces, **lo correcto sería estandarizar las variables para eliminar sus distintas unidades de medida y evitar distorsiones debidas a diversas escalas**, cosa que adrede no hemos hecho en los pasos anteriores. Ahora, vamos a repetir el procedimiento pero estandarizando previamente las variables con `StandardScaler` y compararemos los nuevos resultados con los anteriormente obtenidos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos sklearn para estandarizar la matriz de features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que las variables ahora tengan media 0 y desvío 1.\n",
    "print('Medias:', np.mean(X_train, axis=0).round(2))\n",
    "print('Desvio:', np.std(X_train, axis=0).round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculamos nuevamente los scores de cross validation,\n",
    "# pero esta vez sobre los features estandarizados:\n",
    "\n",
    "scores_para_df_standard = []\n",
    "\n",
    "for i in range(1, 21):\n",
    "    model = KNeighborsClassifier(n_neighbors=i)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    dict_row_score = {'score_medio':np.mean(cv_scores),\n",
    "                      'score_std':np.std(cv_scores), 'n_neighbors':i}\n",
    "    scores_para_df_standard.append(dict_row_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el DataFrame a partir de la lista de diccionarios\n",
    "df_scores_standard = pd.DataFrame(scores_para_df_standard)\n",
    "df_scores_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos nuevamente los límites para graficar\n",
    "df_scores_standard['limite_superior'] = df_scores_standard['score_medio'] + df_scores_standard['score_std']\n",
    "df_scores_standard['limite_inferior'] = df_scores_standard['score_medio'] - df_scores_standard['score_std']\n",
    "df_scores_standard.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos los resultados\n",
    "plt.plot(df_scores_standard['n_neighbors'], df_scores_standard['limite_inferior'], color='r')\n",
    "plt.plot(df_scores_standard['n_neighbors'], df_scores_standard['score_medio'], color='b')\n",
    "plt.plot(df_scores_standard['n_neighbors'], df_scores_standard['limite_superior'], color='r');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificamos el score máximo\n",
    "df_scores_standard.loc[df_scores_standard.score_medio == df_scores_standard.score_medio.max()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si bien el valor de _k_ óptimo vuelve a ser el mismo que antes, notamos que el _score_ promedio de la validación cruzada es varios puntos más alto que el que habíamos alcanzado sin la estandarización de las variables.\n",
    "\n",
    "Ahora que decidimos cuál es el mejor preprocesamiento y el mejor valor posible para el hiperparámetro `n_neighbors`, podemos reentrenar el modelo y evaluar los resultados sobre _test_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignamos el valor del k óptimo a una variable\n",
    "best_k = df_scores_standard.loc[df_scores_standard.score_medio == df_scores_standard.score_medio.max(), 'n_neighbors'].values[0]\n",
    "best_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elegimos el modelo óptimo de acuerdo a las pruebas de cross validation\n",
    "model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "\n",
    "# Lo ajustamos sobre los datos de entrenamiento\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos qué accuracy obtenemos en train\n",
    "accuracy_score(y_train, model.predict(X_train)).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En línea con los resultados que habíamos durante las pruebas de validación cruzada, nuestro KNN está alcanzando un _accuracy score_ del orden del 97% sobre los datos de entrenamiento. Veamos si es capaz de generalizar sobre el conjunto de testeo con una _performance_ similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo utilizamos para predecir en test\n",
    "X_test = scaler.transform(X_test) # ¡Importantísimo estandarizar también los datos de test con las medias y desvíos aprendidos en train!\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluamos el accuracy del modelo en test\n",
    "accuracy_score(y_test, y_pred).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Excelente! Nuestro modelo tiene una muy buena capacidad de generalización, pudiendo clasificar correctamente al 96% de los tumores de *test*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_confusion\"></a>\n",
    "## Matriz de confusión\n",
    "\n",
    "Además de evaluar la capacidad predictiva del modelo a partir del *accuracy*, queremos contar con un poco más de detalle acerca de los resultados de nuestro clasificador. Para esto, generaremos la matriz de confusión, una tabla que muestra los aciertos y desaciertos del modelo.\n",
    "\n",
    "El método `confusion_matrix()`, propio del módulo de métricas de Scikit-Learn, nos permite generar rápidamente una tabla de doble entrada que compara las etiquetas reales (eje vertical) con las etiquetas predichas (eje horizontal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos la matriz de confusión\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Graficar la matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la matriz de confusión para visualizarla mejor\n",
    "sns.heatmap(cm, annot=True)\n",
    "plt.ylabel('Etiquetas reales')\n",
    "plt.xlabel('Etiquetas predichas');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo interpretamos esta tabla?\n",
    "\n",
    "- La primera fila corresponde a los casos negativos reales (tumores malignos) y la segunda, a los casos positivos reales (tumores benignos).\n",
    "- La primera columna corresponde a los casos negativos predichos (tumores malignos) y la segunda, a los casos positivos predichos (tumores benignos).\n",
    "- En la diagonal de la matriz se encuentran las clasificaciones correctas: nuestro modelo detectó correctamente 50 tumores malignos y 87 tumores benignos.\n",
    "- Los elementos por fuera de la diagonal indican las confusiones del modelo (de ahí el nombre de la matriz): nuestro modelo confunde 3 tumores malignos y 3 tumores benignos, asignándoles etiquetas incorrectas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Podemos calcular manualmente la exactitud de nuestro modelo...\n",
    "((cm[0,0] + cm[1,1]) / len(y_pred)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... o computarla utilizando el método del accuracy score\n",
    "accuracy_score(y_test, y_pred).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pese a ser un modelo de _machine learning_ de los más sencillos, aplicando KNN sobre el dataset de cáncer de mama podemos distinguir con un 96% de exactitud los tumores benignos de los malignos.\n",
    "\n",
    "Más adelante, estudiaremos otras métricas de evaluación, distintas al *accuracy*, que también surgen de la matriz de confusión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_conclusion\"></a>\n",
    "## Conclusión\n",
    "\n",
    "<br>\n",
    "<div id=\"caja9\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/kit_de_salida.png\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>Vimos una aplicación de <b>KNN</b> a un problema real, relevante en el ámbito de la medicina: entrenamos un modelo de clasificación que permite distinguir tumores benignos de malignos. Hicimos pruebas para distintos valores del hiperparámetro <i>k</i> del modelo, y elegimos el valor óptimo siguiendo la estrategia de <b>validación cruzada</b>. Mostramos <b>la importancia de estandarizar las <i>features</i></b> como paso necesario en la etapa de preprocesamiento de los datos cuando trabajamos con modelos que se basan en calcular distancias. Por último, presentamos la <b>matriz de confusión</b>, una herramienta fundamental al momento de analizar los resultados de un clasificador.</label></div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
