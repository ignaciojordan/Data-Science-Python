{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../../common/logo_DH.svg\" align='left' width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint Clustering - Solución\n",
    "\n",
    "\n",
    "Vamos a trabajar con un dataset de cáncer de mama elaborado por la Universidad de Wisconsin. Las features fueron calculadas de imágenes digitalizadas de tejido mamario y describen características de los núcleos celulares en las imágenes. Además contamos con una variable categórica que describe si las observaciones corresponden a células benignas o malignas.\n",
    "\n",
    "Para empezar importamos el dataset de sklearn:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "BC = load_breast_cancer()\n",
    "\n",
    "X=BC.data; # Features\n",
    "y_true=BC.target; # Target\n",
    "\n",
    "data=pd.DataFrame(X);\n",
    "data.columns=BC.feature_names\n",
    "\n",
    "data['diagnosis']=y_true;\n",
    "\n",
    "print(BC.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()  # for plot styling\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "from scipy.cluster import hierarchy \n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.metrics import silhouette_score,calinski_harabasz_score,classification_report,confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Visualización\n",
    "\n",
    "Hacé una exploración visual de los datos, para ver si existe una estructura de clusters consistente con las categorías 'Benigna' y 'Maligna'. Los datos tienen 30 dimensiones por lo que hacer un pairplot de todas contra todas se vuelve imposible. Elegí pares de dimensiones que sospeches que puedan ser relevantes y graficá en scatterplots con distinto color las células benignas y malignas. \n",
    "\n",
    "Hay alguna combinación de features que separe visualmente las clases?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data=data,x_vars=['mean radius','mean area','mean symmetry','mean concavity'],\\\n",
    "         y_vars=['mean texture','mean smoothness','mean compactness','mean fractal dimension'],hue='diagnosis',plot_kws={'alpha': 0.5},aspect=1.5);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que típicamente las columnas que tienen que ver con el tamaño (radio, perímetro, área) son buenas predictoras de la clase. A continuación, usemos el scatterplot de radio-textura para evaluar visualmente los clusters que encontremos con diferentes algoritmos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Est*****zación\n",
    "\n",
    "Antes de implementar un algoritmo de clustering, qué hay que hacer con los datos? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos los datos\n",
    "scaler=StandardScaler()\n",
    "X_sc=scaler.fit_transform(X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Kmeans\n",
    "\n",
    "Empecemos por usar Kmeans, variando k entre 2 y 9. Graficá las medidas silhouette y calinski-harabasz en cada caso. \n",
    "\n",
    "¿Qué nos dicen sobre la estructura de los datos? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = []\n",
    "for k in range(2,9):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0) \n",
    "    kmeans.fit(X_sc)\n",
    "    labels = kmeans.labels_\n",
    "    centroids = kmeans.cluster_centers_\n",
    "    #predY = np.choose(labels, pd.Series(range(0,k+1)).astype(np.int64))\n",
    "    silhouette = silhouette_score(X_sc, labels, metric='euclidean')\n",
    "    calinsky = calinski_harabasz_score(X_sc, labels)      \n",
    "    evaluation.append([k, silhouette, calinsky])\n",
    "    #print(\"K= \", evaluation)\n",
    "\n",
    "evaluation=np.array(evaluation);\n",
    "f,ax=plt.subplots(1,2,figsize=(15,6))\n",
    "ax[0].plot(evaluation[:,0],evaluation[:,1]) \n",
    "ax[0].set_ylabel('Silhouette Score')\n",
    "ax[0].set_xlabel('Número de clusters')\n",
    "\n",
    "ax[1].plot(evaluation[:,0],evaluation[:,2]) \n",
    "ax[1].set_ylabel('Calinski-Harabasz Score')    \n",
    "ax[1].set_xlabel('Número de clusters');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Evaluación\n",
    "\n",
    "Dado que conocemos las etiquetas, podemos testear el clustering viendo las métricas que vimos para clasificación.  \n",
    "\n",
    "* Graficá la matriz de confusión comparando las etiquetas reales con las predichas para el caso en que k=2.\n",
    "\n",
    "* Usá la herramienta classification_report de sklearn.metrics para evaluar el resultado mirando distintas métricas. \n",
    "\n",
    "¿Cuál es la métrica más importante en este caso?\n",
    "\n",
    "* Graficá en un scatterplot de mean radius vs mean texture los clusters encontrados. Compará visualmente con el scatterplot del punto 1 en donde usamos las etiquetas reales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2, random_state=0) \n",
    "kmeans.fit(X_sc)\n",
    "labels_km = kmeans.labels_\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_true,labels_km),annot=True,cmap='Blues',fmt=\".0f\",yticklabels=['Benigno','Maligno']);\n",
    "\n",
    "print(classification_report(y_true,labels_km))\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "sns.scatterplot(X_sc[:,0],X_sc[:,1],hue=y_true,ax=ax[0])\n",
    "ax[0].set_title('True labels')\n",
    "sns.scatterplot(X_sc[:,0],X_sc[:,1],hue=labels_km,ax=ax[1])\n",
    "ax[1].set_title('Kmeans')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Clustering Jerárquico\n",
    "\n",
    "* Implementá un modelo de clustering jerárquico usando el método 'ward' y graficá el dendrograma. ¿Se ve una estructura de clusters? ¿cuántos?\n",
    "\n",
    "* Seleccioná dos clusters con la función fcluster().\n",
    "\n",
    "* Graficá la matriz de confusión y el clasification_report para este caso. ¿Cómo performa en relación a kmeans?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Z = linkage(X_sc, 'ward');\n",
    "\n",
    "plt.figure(figsize=[7,7])\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Data points')\n",
    "plt.ylabel('Distance')\n",
    "\n",
    "color_palette=['r','g','y','m','c'];\n",
    "\n",
    "hierarchy.set_link_color_palette(color_palette) \n",
    "\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  \n",
    "    leaf_font_size=5.,  \n",
    "    color_threshold=60,     \n",
    ")\n",
    "plt.hlines(60,0,X_sc.shape[0]*100,linestyle='--')\n",
    "plt.xticks([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_hc=fcluster(Z,2,criterion='maxclust');\n",
    "\n",
    "labels_hc[labels_hc==2]=0;\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(y_true,labels_hc),annot=True,cmap='Blues',fmt=\".0f\",yticklabels=['Benigno','Maligno']);\n",
    "\n",
    "print(classification_report(y_true,labels_hc))\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "sns.scatterplot(X_sc[:,0],X_sc[:,1],hue=y_true,ax=ax[0])\n",
    "ax[0].set_title('True labels')\n",
    "sns.scatterplot(X_sc[:,0],X_sc[:,1],hue=labels_hc,ax=ax[1])\n",
    "ax[1].set_title('Hierarchical Clustering')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. DBSCAN\n",
    "\n",
    "Repetí el el análisis con DBSCAN. Para ello deberás setear los hiperparámetros minPts y eps. \n",
    "\n",
    "\n",
    "* Graficá la curva de k-distancias para definir eps. Recordá que se suele usar k=minPts-1. Mirá la curva para distintos valores de minPts razonables.\n",
    "\n",
    "* Cuántos clusters encuentran con DBSCAN? Depende mucho del valor de los hiperparámetros?\n",
    "\n",
    "* Graficá los scatterplots correspondientes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minPts=20;\n",
    "k=minPts-1;\n",
    "\n",
    "D=squareform(pdist(X_sc));\n",
    "\n",
    "k_distances=np.zeros(D.shape[0]);\n",
    "\n",
    "for i in range(D.shape[0]):\n",
    "    distances=np.sort(D[i]);\n",
    "    k_distances[i]=distances[k];\n",
    "k_distances=np.sort(k_distances);\n",
    "k_distances=k_distances[::-1];\n",
    "    \n",
    "plt.plot(k_distances);\n",
    "plt.xlabel('Rank');\n",
    "plt.ylabel('K-distance');\n",
    "plt.hlines([4,6],0,400,linestyles='dashed');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=5, min_samples=minPts)\n",
    "labels_db = dbscan.fit_predict(X_sc)\n",
    "\n",
    "f,ax=plt.subplots(1,2,figsize=(12,5))\n",
    "sns.scatterplot(X_sc[:,0],X_sc[:,1],hue=y_true,ax=ax[0])\n",
    "ax[0].set_title('True labels')\n",
    "sns.scatterplot(X_sc[:,0],X_sc[:,1],hue=labels_db,ax=ax[1])\n",
    "ax[1].set_title('DBSCAN');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
