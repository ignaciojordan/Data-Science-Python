{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qY-Zcc6hjoE7"
   },
   "source": [
    "# LAB: Pipelines y Transformadores\n",
    "\n",
    "\n",
    "## 1. Introducción\n",
    "En este Lab vamos a crear Pipelines para pre-procesar datos y extraer características sobre el [Titanic dataset](http://www.kaggle.com/c/titanic-gettingStarted/data).\n",
    "\n",
    "El dataset es una lista de pasajeros del trasatlántico más famoso. La segunda columna del dataset (\"survived\") indica si la persona ha sobrevivido (1) o no (0) al naufragio. El resto de las columnas contienen información diversa sobre cada uno de los pasajeros.\n",
    "\n",
    "* Levantamos el dataset (Titanic.csv) en un DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWFEGRoNjoE-",
    "outputId": "66adbd81-f753-48bd-f409-1eb50d3a03c6"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../Data/Titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dpEum7w9joFI"
   },
   "source": [
    "Usemos el método info para dar un vistazo a los datos:\n",
    "\n",
    "- Hay características numéricas?\n",
    "- Hay características categóricas?\n",
    "- Hay datos incompletos? En qué columnas?\n",
    "- Cuáles te parecen importantes para rellenar?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FJLoVc1fjoFK",
    "outputId": "b020f298-333f-4214-8518-9c93607c7c55"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aiY0Gvw6joFR",
    "outputId": "5dd9cfa3-5074-43db-e21d-de9d6329c747"
   },
   "outputs": [],
   "source": [
    "df.Survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nQwh0joojoFZ",
    "outputId": "37de8b64-b8fd-492b-847d-d641fceec5c8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocesando cada grupo de columnas\n",
    "\n",
    "Observamos que el preprocesamiento de los datos requiere distintos enfoques para distintos tipos de columnas: algunas requieren imputación, otras requieren generar variables Dummies y otras sería conveniente estandarizarlas.\n",
    "\n",
    "La idea es armar un pipeline separado para el preprocesamiento que necesita cada grupo de variables y luego unirlos todos con el método [`make_union`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_union.html) que ejecutará todos los pipelines para luego concatenar el resultado.\n",
    "\n",
    "Para hacer las transformaciones de cada grupo de columnas sugerimos crear un transformer de sklearn ColumnSelector que permita seleccionar un grupo de columnas del DataFrame donde queremos aplicar las transformaciones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YV4RfY8MjoFg"
   },
   "source": [
    "## 2. Edad\n",
    "\n",
    "Se puede observar que hay varios pasajeros sin información de edad (columna \"Age\"). Vamos a intentar llenar los datos de esta columna. Exploremos la distribución de valores para los datos existentes y pensemos una estrategia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PaOXG6vojoFh",
    "outputId": "e4aa296a-28c8-4be1-9394-52618d61324d"
   },
   "outputs": [],
   "source": [
    "df.Age.plot(kind = 'hist');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "n2xXPSMSjoFn"
   },
   "source": [
    "### 2.b Transformador de Edad\n",
    "\n",
    "Dependiendo la estrategia que hayamos decido vamos a necesitar imputar los datos de edad faltantes, ya sea usando un transformador del módulo de pre-procesamiento o crear un transformador custom transformer.\n",
    "Esto podría implicar:\n",
    "\n",
    "- Seleccionar una o más columnas\n",
    "- Llenar los datos faltantes\n",
    "- Escalar los valores de Edad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y6yDc8ZYjoFo",
    "outputId": "3f041f02-847d-4e1e-ce1e-3eb314af861b"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ljlv7RSNjoF2"
   },
   "source": [
    "## 3. Variables Categóricas\n",
    "\n",
    "\"Embarked\" y \"Pclass\" son variables categóricas. Usá la función [`get_dummies`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html) de pandas para crear columnas correspondientes a los valores de las mismas.\n",
    "\n",
    "\"Embarked\" tiene un par de datos faltantes. Llenalos con el puerto de embarque más común en el dataset.\n",
    "\n",
    "Sugerencia: Crear un transformador custom que \"envuelva\" el uso de get_dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3vu7BNNjjoGa"
   },
   "source": [
    "## 4. Tarifa\n",
    "\n",
    "Escalar el atributo \"Fare\" (Tarifa) usando uno de los escaladores existentes en el módulo de preprocesamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Otras columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2fydmMlbjoGk"
   },
   "source": [
    "## 6. Union\n",
    "\n",
    "Utilizá una FeatureUnion o la función make_union para combinar todos los pipelines que has creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DlVIi4nXjoGw"
   },
   "source": [
    "## 7. Predicciones\n",
    "\n",
    "Ahora utilicemos GridSearch para evaluar la performance de estas transformaciones, seguidas de un modelo de regresión logística. \n",
    "Para esto exploren distintos valores de parámetros para C.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pimero separar las X y las y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separar los datos de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WbeTjudAjoG1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplicar el `pipeline` con todos los objetos transformadores del dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hTzDh1qojoGy"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MPZBjV2mjoHG"
   },
   "source": [
    "#### Performance sobre datos nuevos\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XjtnsXzsjoHZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Solution_LAB_Pipelines.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
