{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[<img src=\"https://www.digitalhouse.com/ar/logo-DH.png\" width=\"400\" height=\"200\" align='right'>](http://digitalhouse.com.ar/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Motivación**:\n",
    "Esta notebook es un bonus para que observen como generar un algoritmo de descenso por gradiente solamente usando numpy.\n",
    "\n",
    "Recordemos que para el caso lineal solamente queremos calcular iterativamente la siguiente expresión:\n",
    "\n",
    "{$ \\theta_j= \\theta_j - \\alpha\\frac{1}{2m}\\sum_{i=1}^{m}(y_{i}- \\hat y_{i})^{2}$}\n",
    "\n",
    "Es decir en cada paso queremos actualizar el valor del coeficiente simplemente agregandole un termino que puede ser negativo o positivo (la derivada de la función de costo).\n",
    "Probemos como seria eso en python:\n",
    "\n",
    "Generamos una fucion que nos da una relacion lineal con cierto ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genData(numPoints, bias, variance):\n",
    "    import numpy as np\n",
    "    x = np.zeros(shape=(numPoints, 2))\n",
    "    y = np.zeros(shape=numPoints)\n",
    "    # basically a straight line\n",
    "    for i in range(0, numPoints):\n",
    "        # bias feature\n",
    "        x[i][0] = 1\n",
    "        x[i][1] = i\n",
    "        # our target variable\n",
    "        y[i] = (i + bias) + np.random.uniform(0, 1) * variance\n",
    "    return x, y\n",
    "\n",
    "# gen 100 points with a bias of 25 and 10 variance as a bit of noise\n",
    "x, Y = genData(100, 25, 10)\n",
    "X = x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "#regression part: Calculamos los coeficientes a ver si tiene sentido.\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(X,Y)\n",
    "# genero la leyenda\n",
    "line = str(slope) + \"*x +\" + str(intercept)\n",
    "# hago el grafico\n",
    "p = sns.regplot(x=X,y=Y,label=line)\n",
    "# muestro la leyenda.\n",
    "p.legend();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que tenemos una relacion lineal entre estas variables donde la pendiente tiene a 1 y la ordenada al origen a 31."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me genero la rutna de descenso por gradiente\n",
    "def gradient_descent(X, Y, lr=0.0001, epochs=100000):\n",
    "    \n",
    "    '''\n",
    "    Gradient Descent for a single feature\n",
    "    '''\n",
    "    # Building the model\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    import numpy as np\n",
    "    # defino aleatoriamente los betas.\n",
    "    beta0 = 100\n",
    "    beta1 = 100\n",
    "    # lista para exportar evolucion de beta0 y beta1\n",
    "    \n",
    "    beta0_t=[]\n",
    "    beta1_t=[]\n",
    "    mse_t=[]\n",
    "    n = float(len(X)) # Number of elements in X\n",
    "\n",
    "    # Performing Gradient Descent \n",
    "    for _ in range(epochs): \n",
    "        # calculo el y pred.\n",
    "        Y_pred = beta1*X + beta0  # The current predicted value of Y\n",
    "        # calculo el diferecial para cada beta.\n",
    "        D_beta1 = (-2/n) * sum(X * (Y - Y_pred))  # Derivative wrt m\n",
    "        D_beta0 = (-2/n) * sum(Y - Y_pred)  # Derivative wrt c\n",
    "        # actualizo el valor de beta en cada paso.\n",
    "        beta1 = beta1 - lr * D_beta1  # Update m\n",
    "        beta0 = beta0 - lr * D_beta0  # Update c\n",
    "        mse = mean_squared_error(Y,Y_pred)\n",
    "        # guardo la evolucion de los betas y la funcion de costo.\n",
    "        beta0_t.append(beta0)\n",
    "        beta1_t.append(beta1)\n",
    "        mse_t.append(mse)\n",
    "    return beta0,beta1,beta0_t,beta1_t,mse_t\n",
    "    \n",
    "intercept,slope,beta0_t,beta1_t,mse_t=gradient_descent(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('slope:     %10.3f \\nintercept: %10.3f' %(slope,intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(14,10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(beta0_t)\n",
    "plt.ylabel('beta0')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(beta1_t)\n",
    "plt.ylabel('beta1')\n",
    "plt.xlabel('epochs')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(beta0_t,mse_t)\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('beta0')\n",
    "\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(beta1_t,mse_t)\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('beta1')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En función de los pasos de iteraccion (epochs) vean como converge al valor del beta 0 y 1 o ordenada al origen y pendiente respectivamente.\n",
    "\n",
    "**Conclusión**: COn solo una simple rutina nos generamos un algoritmo que calcula la pendiente y la ordenada al origen de manera muy fácil."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
