{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "        \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<img src='../../../common/logo_DH.png' align='left' width=35%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Machine Learning - Aprendizaje no supervisado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla de Contenidos\n",
    "\n",
    "1. <a href=\"#section_introduccion\">Introducción</a>\n",
    "2. <a href=\"#section_no_supervisado\">Aprendizaje no supervisado</a>\n",
    "- 2.1 <a href=\"#section_clustering\">Clustering</a>\n",
    "- 2.2 <a href=\"#section_reduccion\">Reducción de la dimensionalidad</a>\n",
    "3. <a href='#section_recap'>Recapitulando</a>\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_introduccion\"></a>\n",
    "## Introducción\n",
    "<img src=\"img/sklearn.png\" width=\"450\">\n",
    "<br>\n",
    "\n",
    "Ya hemos visto ejemplos sencillos de problemas de aprendizaje supervisado, donde buscamos predecir a partir de ciertas _features_ una variable _target_ que puede ser continua (problemas de regresión) o categórica (clasificación). Tuvimos un primer contacto con la biblioteca Scikit-Learn, la herrramienta por excelencia para trabajar con _machine learning_ en Python.\n",
    "\n",
    "**En esta notebook, exploraremos el aprendizaje no supervisado**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_no_supervisado\"></a>\n",
    "## Aprendizaje no supervisado\n",
    "\n",
    "<div id=\"caja9\" style=\"float:left;width: 85%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label>Comencemos repasando en qué consiste este otro tipo de <i>machine learning</i><br></label></div>\n",
    "\n",
    "El aprendizaje no supervisado **se caracteriza por prescindir de una variable _target_. El foco está puesto en descubrir patrones o estructuras subyacentes en la información que nos permitan generar _insights_ relevantes en una estructura de datos que, a priori, no son evidentes.** Dentro del aprendizaje no supervisado, se engloban las técnicas de **_clustering_** y las de **reducción de la dimensionalidad**.<br>\n",
    "\n",
    "Veremos un ejemplo de cada una de ellas a partir del dataset de [Iris](https://es.wikipedia.org/wiki/Conjunto_de_datos_flor_iris), sobre el cual ya estuvimos trabajando anteriormente para entrenar nuestro primer modelo de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://shahinrostami.com/images/ml-with-kaggle/iris-2338142_960_720-1.jpg\">\n",
    "<center><i>La flor iris</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos cargar el dataset desde la librería Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspeccionamos la tabla y describimos la información:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizamos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris, hue='species');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_seguir_pensando.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>¿Qué apreciamos en estos gráficos? ¿Existen patrones relevantes que surjan a simple vista? ¿Se aprecian grupos de observaciones distinguibles fácilmente entre sí?</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_clustering\"></a>\n",
    "### Clustering\n",
    "\n",
    "Los algoritmos de _clustering_ nos permiten segmentar las observaciones asignándolas automáticamente a distintos grupos o _clusters_, de forma de que observaciones similares se encuentren agrupadas y que los grupos formados sean más bien distintos entre sí. Algunas aplicaciones frecuentes de este tipo de análisis son la segmentación de una cartera de clientes de una compañía o la identificación de expresiones genéticas similares en estudios biológicos.\n",
    "\n",
    "En este caso, vamos a aplicar una **técnica clásica de _clustering_** llamada **K-Means** al dataset de Iris. Este algoritmo trata de encontrar grupos de observaciones más bien homogéneas entre sí sin tener referencias a etiquetas en los datos. La cantidad de _clusters_ que obtenemos debe ser especificada de antemano. Vamos a analizar si los grupos o _clusters_ que obtenemos responden a las distintas especies -como esperaríamos- o no.\n",
    "\n",
    "El algoritmo de K-Means se puede resumir básicamente en una serie de pasos:\n",
    "\n",
    "1. Asignar aleatoriamente los puntos centrales (centroides) de los _k clusters_ que se desean obtener.\n",
    "2. Calcular la distancia de las observaciones a estos puntos centrales y asignar cada muestra al _cluster_ cuyo centroide resulta ser el más cercano.\n",
    "3. Recalcular la posición del punto central usando la asignación actual de observaciones de cada _cluster_.\n",
    "4. Iterar los pasos 2 y 3 hasta alcanzar algún criterio de convergencia.\n",
    "\n",
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/para_saber_mas.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label>Si bien no ahondaremos en demasiados detalles, <a href=\"http://shabal.in/visuals/kmeans/left.gif\">esta animación</a> nos permite generar una intuición visual acerca del comportamiento de <b>K-Means</b>.</label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notemos que, pese a tratarse de un problema no supervisado, el paso a paso con Scikit-Learn que seguiremos a continuación es prácticamente igual al que hemos visto anteriormente:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "source": [
    "##### **1. Seleccionamos una clase de modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "source": [
    "##### **2. Elegir los hiperparámetros del modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=3, random_state=0) # n_clusters define cuántos clusters queremos obtener y random_state controla la aleatoriedad inicial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lu4UNSVBm-j"
   },
   "source": [
    "##### **3. Preparar los datos en una matriz de _features_**\n",
    "\n",
    "Como se trata de un problema no supervisado, por definición, no contaremos con una variable objetivo. Por eso, construimos la matriz de _features_ descartando la variable species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3lu4UNSVBm-j"
   },
   "outputs": [],
   "source": [
    "X_iris = iris.drop('species', axis=1)\n",
    "X_iris.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que K-Means es un algoritmo que trabaja calculando distancias, un paso previo al ajuste del modelo consiste en **estandarizar los valores**, de forma de eliminar posibles inconvenientes asociados a la escala de las distintas variables. Éste es un paso de **preprocesamiento de los datos** que será frecuente en muchas de las aplicaciones que estudiaremos en el curso.\n",
    "\n",
    "Numerosas herramientas de preprocesamiento se encuentran en el módulo de [`preprocessing`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing) de Scikit-Learn. De allí, importamos la clase **`StandardScaler()`**, un **transformador** de los datos que reescala las variables para que tengan **media 0 y desvío estándar 1**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F91clTIQE7l9"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F91clTIQE7l9"
   },
   "source": [
    "Al tratarse de una clase, también es necesario instanciarla en un objeto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F91clTIQE7l9"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F91clTIQE7l9"
   },
   "source": [
    "Los transformadores también se ajustan a los datos, al igual que los estimadores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F91clTIQE7l9"
   },
   "outputs": [],
   "source": [
    "scaler.fit(X_iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F91clTIQE7l9"
   },
   "source": [
    "A diferencia de los estimadores, en lugar del método `predict()`, los transformadores tienen el método `transform()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F91clTIQE7l9"
   },
   "outputs": [],
   "source": [
    "scaler.transform(X_iris)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asignamos los resultados a una matriz X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.transform(X_iris)\n",
    "print('Medias reescaladas:', np.mean(X, axis=0).round(2))\n",
    "print('Desvíos reescalados:', np.std(X, axis=0).round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como el fin último de este tipo de análisis es generar grupos de observaciones únicamente a partir de sus características, sin tener presente ningún tipo de variable objetivo, en los problemas de _clustering_ (y de aprendizaje no supervisado en general) no es necesario hacer la separación de los conjuntos de entrenamiento y testeo. Por eso, en este punto, ya estamos listos para hacer el ajuste del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "source": [
    "##### **4. Ajustar el modelo a los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "outputs": [],
   "source": [
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/haciendo_foco.png\" style=\"align:center\"/> </div>\n",
    "  <br>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>Notar que no especificamos ninguna variable $y$.</b></label></div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "source": [
    "##### **5. Predecir etiquetas**\n",
    "\n",
    "En este caso, la predección consiste en generar etiquetas que identifiquen cada observación con un _cluster_ en particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "outputs": [],
   "source": [
    "y_km = model.predict(X)\n",
    "y_km"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b2s2VPpDFZHW"
   },
   "outputs": [],
   "source": [
    "# Visualizamos los resultados\n",
    "X_iris['cluster'] = y_km\n",
    "sns.pairplot(X_iris, hue='cluster');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7xLBswdWGLn7"
   },
   "source": [
    "Comparando los dos _pair plot_ que hemos graficado, podemos observar que la segmentación de flores resultante del análisis de _clustering_ guarda una estrecha relación con las etiquetas reales, incluso aunque K-Means jamás las observó durante el ajute a los datos.\n",
    "\n",
    "Esto significa que aun sin un experto que nos indique las etiquetas de las flores individuales, las _features_ de estas observaciones son lo suficientemente distintivas para que podamos identificar *automáticamente* las diferentes especies con un simple algoritmo de _clustering_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"section_reduccion\"></a>\n",
    "### Reducción de la dimensionalidad\n",
    "\n",
    "Las técnicas de reducción de la dimensionalidad buscan obtener a partir de un dataset complejo, con numerosas variables (alta dimensionalidad), una representación en una menor cantidad de variables (baja dimensionalidad) que de alguna manera preserve cualidades relevantes del dataset original. Estas técnicas son muy utilizadas en la etapa de análisis exploratorio de los datos para poder generar visualizaciones interesantes de todas las variables en tan sólo dos o tres dimensiones. También, muchas veces se las utiliza como parte del preprocesamiento de los datos, de forma de obtener nuevas _features_ que alimenten a otro tipo de algoritmos supervisados o no supervisados.\n",
    "\n",
    "Como un ejemplo de un problema de aprendizaje no supervisado, veamos cómo reducir la dimensionalidad de los datos del dataset Iris para poder visualizarlos más fácilmente.\n",
    "\n",
    "Como hemos visto, el dataset consta de 150 muestras de 3 especies de la flor Iris, de las cuales disponemos de 4 atributos: el largo y ancho del pétalo y del sépalo.\n",
    "\n",
    "Por lo tanto, el dataset Iris es cuatridimensional: hay 4 _features_ medidas para cada observación (*sample*).\n",
    "\n",
    "La tarea de reducción de la dimensionalidad es investigar si hay una representación apropiada de baja dimensionalidad que retiene las características esenciales de los datos originales. \n",
    "\n",
    "En este ejemplo, vamos a usar **Principal Component Analysis (PCA)**, una técnica rápida de reducción lineal de la dimensionalidad. Cada componente obtenido es una combinación lineal de todas las variables, donde algunas tienen mayor peso que otras según el caso.\n",
    "\n",
    "Siguiendo la secuencia de pasos presentada previamente, tenemos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uh8fhWPYqgB"
   },
   "source": [
    "##### **1. Seleccionamos una clase de modelo**\n",
    "\n",
    "PCA trabaja con métodos de descomposición de matrices, de ahí que se encuentre en el módulo [`decomposition`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.decomposition) de Scikit-Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uh8fhWPYqgB"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Hua9z2EQYqgY"
   },
   "source": [
    "##### **2. Elegir los hiperparámetros del modelo**\n",
    "\n",
    "Vamos a pedirle al modelo que devuelva dos componentes, es decir, una representación bidimensional de los datos originales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uh8fhWPYqgB"
   },
   "outputs": [],
   "source": [
    "model = PCA(n_components=2)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **3. Preparar los datos en una matriz de _features_**\n",
    "\n",
    "Como PCA requiere un preprocesamiento similar a K-Means, en este punto podemos reutilizar nuestra matriz X anteriormente definida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uh8fhWPYqgB"
   },
   "source": [
    "##### **4. Ajustar el modelo a los datos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uh8fhWPYqgB"
   },
   "outputs": [],
   "source": [
    "model.fit(X)       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **5. Predecir etiquetas**\n",
    "\n",
    "En este caso, la predección consiste en generar los componentes principales a partir de las variables originales. Al igual que en el caso de `StandardScaler`, cuando trabajamos con modelos de reducción de la dimensionalidad, esto se logra con el método `transform()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2uh8fhWPYqgB"
   },
   "outputs": [],
   "source": [
    "X_2D = model.transform(X)\n",
    "X_2D[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lFb8CM87YqgJ"
   },
   "source": [
    "Ahora vamos a plotear los resultados. Una forma rápida de hacer esto es insertar los resultados en el ``DataFrame`` original de Iris, y usar el método ``lmplot`` de Seaborn para mostrar los resultados:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1157,
     "status": "ok",
     "timestamp": 1537137708778,
     "user": {
      "displayName": "Paolo Donizetti",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "102274939882416466592"
     },
     "user_tz": 180
    },
    "id": "nrsPYCOHYqgO",
    "outputId": "551f27a5-45af-4b6d-ef2d-640e23eba974"
   },
   "outputs": [],
   "source": [
    "iris['PCA1'] = X_2D[:, 0]\n",
    "iris['PCA2'] = X_2D[:, 1]\n",
    "sns.lmplot(\"PCA1\", \"PCA2\", hue='species', data=iris, fit_reg=False);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P0IXNfq9YqgW"
   },
   "source": [
    "Vemos que en la representación en dos dimensiones, las especies están relativamente bien separadas... ¡incluso aunque el algoritmo PCA no tenía conocimiento de las etiquetas de las especies de flores!\n",
    "\n",
    "Esto significa que es posible condensar la información de las cuatro _features_ originales en dos variables nuevas que se construyen a partir de todas ellas y que buscan preservar la esencia de la información que están condensando."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CwfCPPpCYqhD"
   },
   "source": [
    "<a id=\"section_recap\"></a>\n",
    "## Recapitulando\n",
    "\n",
    "Hemos tenido nuestro primer contacto con aplicaciones de _machine learning_ no supervisado con Scikit-Learn. Este tipo de aprendizaje se caracteriza por la ausencia de una variable objetivo. El objetivo del aprendizaje no supervisado consiste en descubrir patrones o estructuras subyacentes en la información que nos permitan **segmentar las observaciones (_clustering_) o generar representaciones de los datos en una menor dimensionalidad**. Trabajamos con el algoritmo **K-Means** para identificar _clusters_ de flores Iris y y utilizamos **PCA** para generar dos nuevas variables que nos permitieron representar en sólo dos dimensiones la información intrínseca de las cuatro _features_ registradas para cada una de las flores.\n",
    "\n",
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/en_resumen.png\" style=\"align:left\"/> </div>\n",
    "  <br>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>A esta altura, ya hemos cubierto a grandes rasgos los distintos tipos de aprendizajes posibles, las características esenciales de la representación de datos y el flujo de trabajo típico de Scikit-Learn.</b></label></div>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "Sin importar el tipo de estimador, el mismo patrón de importar-instanciar-ajustar-predecir se mantiene en todos los casos, aunque con algunas diferencias que van a depender del tipo de problema con el que estemos trabajando.\n",
    "\n",
    "Con estas nuevas herramientas, ya podés explorar la documentación de Scikit-Learn y comenzar a probar varios modelos sobre tus datos, teniendo siempre presente qué tipo de pregunta deseás responder:\n",
    "\n",
    "<div id=\"caja10\" style=\"float:left;width: 100%;\">\n",
    "  <div style=\"float:left;width: 15%;\"><img src=\"../../../common/icons/ponete_a_prueba.png\" style=\"align:left\"/> </div>\n",
    "  <div style=\"float:left;width: 85%;\"><label><b>- ¿Tengo una variable objetivo o pretendo hallar estructuras suyacentes en los datos para enriquecer el análisis?<br/>\n",
    "- ¿Quiero predecir un valor continuo o categórico?<br/>\n",
    "- ¿Deseo segmentar las observaciones?<br/>\n",
    "- ¿Cómo puedo generar visualizaciones que condensen la esencia de los datos?</b></label></div>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
