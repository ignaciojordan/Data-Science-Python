{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial setup\n",
    "try:\n",
    "    # settings colab:\n",
    "    import google.colab\n",
    "    \n",
    "except ModuleNotFoundError:    \n",
    "    # settings local:\n",
    "    %run \"../../../common/0_notebooks_base_setup.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../../../common/logo_DH.svg\" align='left' width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regresión Logística - Práctica Independiente\n",
    "## Tabla de Contenidos\n",
    "\n",
    "- [1. Introducción](#intro)\n",
    "- [2. Predicción de enfermedades cardíacas](#pred)\n",
    "    - [2.1. Descripción del dataset](#descripcion)\n",
    "    - [2.2. EDA - Exploratory data analysis](#eda)\n",
    "    - [2.3. Clasificación de pacientes](#clf)\n",
    "        - [2.3.1. Preparación de los datos](#prep)\n",
    "        - [2.3.2. Ajuste del modelo](#fit)\n",
    "        - [2.3.3. Evaluación del modelo](#eval)\n",
    "        - [2.3.4. Optimización del modelo](#opt)       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "## Introducción\n",
    "En 1948 en Framingham, un pequeño pueblo en Massachusetts, Estados Unidos, comenzó uno de los estudios médicos más famosos de la historia y que aun continua vigente. El estudio, conocido también como Framingham Heart Study, consistió en la participación voluntaria de 3 generaciones de habitantes del pueblo, quienes fueron sometidos a estudios médicos regulares cada 3 a 5 años, generando un gran volumen de datos sobre la salud mental y física, especialmente de enfermedades cardiovasculares de todos los involucrados.<br>\n",
    "Los aportes de este estudio son numerosos, entre los cuales se destacan las relaciones entre el riesgo de tener una enfermedad cardíaca con varios aspectos de la vida cotidiana y del estado de salud general de las personas, tales como la presión sanguínea, los niveles de colesterol, el consumo de cigarrillos y factores psico-sociales. El término \"factor de riesgo\" fue acuñado como parte de los hallazgos de este estudio. \n",
    "Para más información sobre el estudio se puede ingresar a su sitio web https://framinghamheartstudy.org/.\n",
    "El dataset puede ser descargado de https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset\n",
    "\n",
    "<a id=\"pred\"></a>\n",
    "## Predicción de enfermedades cardíacas\n",
    "En esta práctica trabajaremos con un extracto del dataset resultante del estudio, en el que se cuenta con información médica de varios participantes, entre la que se encuentra el riesgo de que esa persona tenga una enfermedad coronaria durante los próximos 10 años. Nos propondremos entrenar un regresor logístico que permita clasificar y identificar los pacientes en riesgo de tener este tipo de enfermedad basándonos en sus datos clínicos.\n",
    "\n",
    "<a id=\"descripcion\"></a>\n",
    "### Descripción del dataset\n",
    "El dataset cuenta con las siguientes variables:\n",
    "- age: Edad.\n",
    "- male: Género.\n",
    "- education: 1 = Some High School; 2 = High School or GED; 3 = Some College or Vocational School; 4 = college\n",
    "- currentSmoker: Si la persona fuma o no\n",
    "- cigsPerDay: la cantidad de cigarrillos que la persona fuma por día en promedio.\n",
    "- BPMeds: si la persona consume medicación para la presión sanguínea.\n",
    "- prevalentStroke: Si la persona tuvo un infarto anteriormente.\n",
    "- prevalentHyp: si la persona tiene hipertensión.\n",
    "- diabetes: si la persona tuvo diabetes.\n",
    "- totChol: nivel de colesterol total.\n",
    "- sysBP: presión sanguínea sistólica.\n",
    "- diaBP:: presión sanguínea diastólica.\n",
    "- BMI: índice de masa corporal.\n",
    "- heartRate: frecuencia cardíaca.\n",
    "- glucose: nivel de glucosa en sangre.\n",
    "- TenYearCHD: si la persona está en riesgo de tener una enfermedad coronaria dentro de los próximos 10 años.\n",
    "\n",
    "Para obtener más información sobre las variables, buscar en https://www.kaggle.com/amanajmera1/framingham-heart-study-dataset\n",
    "\n",
    "<a id=\"eda\"></a>\n",
    "### EDA - Exploratory data analysis\n",
    "Importar el dataset y realizar un análisis exploratorio del mismo. \n",
    "- ¿Cuántos registros hay?\n",
    "- ¿Qué tipo de variable es cada una?\n",
    "- ¿Hay valores faltantes?\n",
    "- ¿Hay valores fuera del rango esperado?\n",
    "- ¿En qué tipo de dato están almacenados?\n",
    "- ¿Todas las variables son médicas o hay otra información en el dataset?\n",
    "- ¿Hay correlación entre las variables?\n",
    "- ¿En qué rango está cada una?\n",
    "- Cómo son las proporciones de las variables categóricas?\n",
    "\n",
    "Realizar las visualizaciones adecuadas para responder estas preguntas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../Data/framingham.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay 4240 registros de los cuales 582 tienen valores faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "582/4240*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=3, ncols=5, figsize=(18,12))\n",
    "fig.suptitle('Histogramas normalizados')\n",
    "for c, ax in zip(df.columns[:-1], axes.flatten()):\n",
    "    sns.distplot(df.loc[df['TenYearCHD']==0, c].dropna(), norm_hist=True, kde=False, ax=ax)\n",
    "    sns.distplot(df.loc[df['TenYearCHD']==1, c].dropna(), norm_hist=True, kde=False, ax=ax)\n",
    "    ax.legend(['TenYearCHD = 0', 'TenYearCHD = 1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,12))\n",
    "sns.heatmap(df.corr()[['TenYearCHD']], annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"clf\"></a>\n",
    "### Clasificación de pacientes\n",
    "Ahora utilizaremos una regresión logística como clasificador de personas y el objetivo será etiquetar a aquellas que tengan riesgo de padecer una enfermedad coronaria en los próximos 10 años.\n",
    "<a id=\"prep\"></a>\n",
    "#### Preparación de los datos\n",
    "¿Qué debemos hacer con el dataset antes de entrenar el modelo?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos los registros con valores faltantes ya que son sólo un 13% del dataset\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparamos la matriz de features y el vector objetivo\n",
    "X = df.drop(columns=['TenYearCHD'])\n",
    "y = df['TenYearCHD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos un set de testeo para evaluar el modelo\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificamos que coincidan las proporciones del target\n",
    "y_train.mean(), y_test.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Estandarizamos los datos para que la regularización sea correcta\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"fit\"></a>\n",
    "#### Ajuste del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"eval\"></a>\n",
    "#### Evaluación del modelo\n",
    "Con el modelo entrenado podemos comenzar a evaluar su performance y ver si podemos hacer algo para mejorarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, lr.predict(X_train_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, lr.predict(X_train_std)), annot=True, fmt='4d')\n",
    "plt.xlabel('Predichos')\n",
    "plt.ylabel('Reales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que hay una accuracy del 85%, pero que de los 418 casos positivos, sólo 32 (7.6%) están siendo detectados. Esto implica que nuestro clasificador le está diciendo a mucha gente que está fuera de peligro cuando en realidad no es así. Intentemos modificar el modelo para mejorar la predicción en estos casos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"opt\"></a>\n",
    "#### Optimización del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.predict_proba(X_train_std[y_train==0])[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograma de probabilidades\n",
    "sns.distplot(lr.predict_proba(X_train_std[y_train==0])[:,1])\n",
    "sns.distplot(lr.predict_proba(X_train_std[y_train==1])[:,1])\n",
    "ylim = plt.ylim()\n",
    "plt.vlines(0.5, ylim[0], ylim[1])\n",
    "plt.ylim(ylim)\n",
    "plt.legend(['Umbral', 'TenYearCHD = 0', 'TenYearCHD = 1'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la naturaleza del probelma, conviene utilizar una estrategia que impida clasificar como pacientes sanos a aquellos que están en riesgo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "umbral = 0.2\n",
    "probs = lr.predict_proba(X_train_std)[:,1]\n",
    "y_pred_train = probs > umbral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_train, y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(confusion_matrix(y_train, y_pred_train), annot=True, fmt='4d')\n",
    "plt.xlabel('Predichos')\n",
    "plt.ylabel('Reales')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modificando el umbral de decisión, baja considerablemente la exactitud del modelo, pero ahora detecta correctamente 225 (53.8%) de los casos positivos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
